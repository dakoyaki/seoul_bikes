{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "seoul_bikes.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EgUvIS54fG4u",
        "wS2EYtzBfHTk"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiixLz2xfG0H"
      },
      "source": [
        "# Bike Sharing Demand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynhEdNWhfG09"
      },
      "source": [
        "###Data Understanding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N2vZ3W8fG0_",
        "outputId": "b8d17357-83bc-46cb-cf1b-06d0adede339",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install skits\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import pickle\n",
        "from scipy.stats import kruskal, pearsonr, randint, uniform, chi2_contingency, boxcox\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, FunctionTransformer, StandardScaler, power_transform\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_squared_log_error, mean_absolute_error\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, TimeSeriesSplit, RandomizedSearchCV, GridSearchCV, cross_val_predict\n",
        "from datetime import datetime\n",
        "from statsmodels.tsa.stattools import grangercausalitytests, adfuller, kpss, acf, pacf\n",
        "from collections import defaultdict, OrderedDict\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
        "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
        "from sklearn.decomposition import PCA\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from skits.feature_extraction import AutoregressiveTransformer\n",
        "from skits.preprocessing import ReversibleImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import xgboost as xgb\n",
        "\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: skits in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from skits) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from skits) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->skits) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->skits) (0.17.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbXB3v-_fG1D"
      },
      "source": [
        "# diplaying all columns without truncation in dataframes\n",
        "pd.set_option('display.max_columns', 500)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s3YvZmxfG1M"
      },
      "source": [
        "#### Loading the data and visualizing and describing it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "oJy-rTgJfG1U"
      },
      "source": [
        "# read in bike sharing dataset\n",
        "bike_df = pd.read_csv('/content/bike_sharing_dataset.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECkD1nPqfG35"
      },
      "source": [
        "# fill NAs with 0 where applicable\n",
        "bike_df['holiday'] = bike_df['holiday'].fillna(0)\n",
        "bike_df['holiday'] = bike_df['holiday'].astype('int')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oyAEfvYfG4V"
      },
      "source": [
        "# function to create seasons for dataframe\n",
        "def seasons(df):\n",
        "   # create a season features\n",
        "    df['season_spring'] = df['Date'].apply(lambda x: 1 if '03' in x[5:7] else 1 if '04' in x[5:7] else 1 \n",
        "                                                     if '05' in x[5:7] else 0)\n",
        "    df['season_summer'] = df['Date'].apply(lambda x: 1 if '06' in x[5:7] else 1 if '07' in x[5:7] else 1 \n",
        "                                                     if '08' in x[5:7] else 0)\n",
        "    df['season_fall'] = df['Date'].apply(lambda x: 1 if '09' in x[5:7] else 1 if '10' in x[5:7] else 1 \n",
        "                                                     if '11' in x[5:7] else 0)\n",
        "    df['season_winter'] = df['Date'].apply(lambda x: 1 if '12' in x[5:7] else 1 if '01' in x[5:7] else 1 \n",
        "                                                     if '02' in x[5:7] else 0)\n",
        "    \n",
        "    return df\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqzbZ7MEfG4X"
      },
      "source": [
        "### create new features for seasons\n",
        "bike_df = seasons(bike_df)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkqz0141fG4a"
      },
      "source": [
        "### create new feature weekday\n",
        "bike_df['date_datetime'] = bike_df['Date'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d\"))\n",
        "bike_df['weekday'] = bike_df['date_datetime'].apply(lambda x: x.weekday())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R2o4uLufG4j"
      },
      "source": [
        "### one hot encode the feature weekday\n",
        "## 0 = Monday, 1 = Tuesday, 2 = Wednesday, etc...\n",
        "weekday_dummies = pd.get_dummies(bike_df['weekday'], prefix='weekday', drop_first=True)\n",
        "bike_df = bike_df.join(weekday_dummies, how='left')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJlqxtHpfG4l"
      },
      "source": [
        "### create new feature working_day\n",
        "bike_df['working_day'] = bike_df['weekday'].apply(lambda x: 0 if x > 5 or x == 0 else 1)\n",
        "bike_df['working_day'] = bike_df[['holiday', 'working_day']].apply(\n",
        "    lambda x: 0 if x['holiday'] == 1 else x['working_day'], axis=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "spfyG3L_fG4s"
      },
      "source": [
        "# drop columns that are irrelevant\n",
        "bike_df.drop(columns=['City', 'ID', 'DistrictKOR', 'DistrictENG', \n",
        "                      'Area(m2)','Bike_Time_NONZERO_SUM',\t'Bike_Time_NONZERO_Mean',\t\n",
        "                      'Bike_Distance_NONZERO_SUM',\t'Bike_Distance_NONZERO_Mean', \n",
        "                      'Trip_Count_NONZERO', 'Bike_Time_SUM', 'BIKE_TIME_MEAN', \n",
        "                      'Bike_Distance_SUM', 'BIKE_DISTANCE_MEAN'], inplace=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWWZDZcqfG8T"
      },
      "source": [
        "# create a new dataframe that encodes the weekday feature with 0 for monday through friday\n",
        "# and 1 for saturday and sunday\n",
        "weekend_distinct_df = bike_df.copy()\n",
        "weekend_distinct_df['weekday'] = weekend_distinct_df['weekday'].apply(lambda x: 1 if (x == 6 or x == 0) else 0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkrnA_PMHYUV"
      },
      "source": [
        "bike_df.drop(columns=['WinddirectM(deg)'], inplace=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vnhF3ikfHCv"
      },
      "source": [
        "# get list for all correlations between a feature and Trip_Count with different rolling means\n",
        "def best_window(x, y, max_window):\n",
        "    corr_temp_cust = []\n",
        "    for i in range(1, max_window):\n",
        "        roll_val = list(x.rolling(i).mean()[i-1:-1])\n",
        "        Trip_Count_ti = list(y[i:])\n",
        "        corr, p_val = pearsonr(Trip_Count_ti, roll_val)\n",
        "        corr_temp_cust.append(corr)\n",
        "    # get the optimal window size for rolling mean between a feature and Trip_Count\n",
        "    max_val = np.argmax(corr_temp_cust)\n",
        "    min_val = np.argmin(corr_temp_cust)\n",
        "    opt_corr_min = corr_temp_cust[min_val]\n",
        "    opt_corr_max = corr_temp_cust[max_val]\n",
        "    \n",
        "    results = {max_val+1: opt_corr_max, min_val+1: opt_corr_min}\n",
        "    \n",
        "    return results\n",
        "    "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j8sGCyEfHFb"
      },
      "source": [
        "# get list for all correlations between a feature and Trip_Count with different rolling standard deviations\n",
        "def best_window_std(x, y, max_window):\n",
        "    corr_temp_cust = []\n",
        "    for i in range(2, max_window):\n",
        "        roll_val = list(x.rolling(i).std()[i-1:-1])\n",
        "        Trip_Count_ti = list(y[i:])\n",
        "        corr, p_val = pearsonr(Trip_Count_ti, roll_val)\n",
        "        corr_temp_cust.append(corr)\n",
        "    # get the optimal window size for rolling std between a feature and Trip_Count\n",
        "    max_val = np.argmax(corr_temp_cust)\n",
        "    min_val = np.argmin(corr_temp_cust)\n",
        "    opt_corr_min = corr_temp_cust[min_val]\n",
        "    opt_corr_max = corr_temp_cust[max_val]\n",
        "    \n",
        "    results = {max_val+1: opt_corr_max, min_val+1: opt_corr_min}\n",
        "    \n",
        "    return results\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVzkAGjyfHGg",
        "outputId": "5828409a-c24e-4590-e998-fc907ecc71f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get the optimal window for rolling std for Trip_Count\n",
        "print(best_window_std(bike_df['Trip_Count'], bike_df['Trip_Count'], 40))\n",
        "\n",
        "# get the correlation for window size determined by Trip_Count\n",
        "cust_mean = bike_df['Trip_Count'].rolling(8).std()[7:-1]\n",
        "pearsonr(cust_mean, bike_df['Trip_Count'][8:])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{21: 0.7458671048146939, 1: 0.3185045110199073}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5909874097580865, 0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP0uUwbZfHGp",
        "outputId": "792634c9-928b-4d1e-fe7f-baf16fc6e062",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get the optimal number for rolling mean for Trip_Count\n",
        "print(best_window(bike_df['Trip_Count'], bike_df['Trip_Count'], 40))\n",
        "\n",
        "# get the correlation for window size determined by Trip_Count\n",
        "cust_mean = bike_df['Trip_Count'].rolling(8).mean()[7:-1]\n",
        "pearsonr(cust_mean, bike_df['Trip_Count'][8:])\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{7: 0.8878801976300186, 39: 0.8177747047009136}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8863948653212457, 0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqgeoPs8fHGs"
      },
      "source": [
        "# add the value from t-1\n",
        "bike_df['Trip_Count_t-1'] = bike_df['Trip_Count'].shift()\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfARS8k1fHGw"
      },
      "source": [
        "# create series that group the mean temperature per season\n",
        "temp_spring = bike_df.groupby('season_spring')['TempM(°C)'].mean().rename({1: 'Spring'})\n",
        "temp_summer = bike_df.groupby('season_summer')['TempM(°C)'].mean().rename({1: 'Summer'})\n",
        "temp_fall = bike_df.groupby('season_fall')['TempM(°C)'].mean().rename({1: 'Fall'})\n",
        "temp_winter = bike_df.groupby('season_winter')['TempM(°C)'].mean().rename({1: 'Winter'})\n",
        "\n",
        "# add them to one series and drop the rows with index 0\n",
        "temp_seasons = temp_summer.append(temp_fall).append(temp_winter).append(temp_spring)\n",
        "temp_seasons.drop(labels=[0], inplace=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSXWES_ofHHv"
      },
      "source": [
        "# create series that groups average users per season\n",
        "cust_spring = bike_df.groupby('season_spring')['Trip_Count'].mean().rename({1: 'Spring'})\n",
        "cust_summer = bike_df.groupby('season_summer')['Trip_Count'].mean().rename({1: 'Summer'})\n",
        "cust_fall = bike_df.groupby('season_fall')['Trip_Count'].mean().rename({1: 'Fall'})\n",
        "cust_winter = bike_df.groupby('season_winter')['Trip_Count'].mean().rename({1: 'Winter'})\n",
        "\n",
        "# add them to one series and drop the rows with index 0\n",
        "cust_seasons = cust_summer.append(cust_fall).append(cust_winter).append(cust_spring)\n",
        "cust_seasons.drop(labels=[0], inplace=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jR9JcMxfHJL",
        "outputId": "be78278c-4b32-4624-a210-e02a69ab78b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get the optimal window for rolling std for temperature\n",
        "print(best_window_std(bike_df['TempM(°C)'], bike_df['Trip_Count'], 40))\n",
        "\n",
        "# get the correlation for window size determined by TempM(°C)\n",
        "temp_mean = bike_df['TempM(°C)'].rolling(8).std()[7:-1]\n",
        "pearsonr(temp_mean, bike_df['Trip_Count'][8:])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: -0.11818513201317055, 31: -0.279594519569663}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.2260233053368831, 5.0153556185029124e-141)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbVJwHnHfHJN",
        "outputId": "05627cc5-7429-46eb-f709-fecc98dac046",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get the optimal window for rolling mean for temperature\n",
        "best_window(bike_df['TempM(°C)'], bike_df['Trip_Count'], 40)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{6: 0.38647683685028433, 39: 0.3383048120182877}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDGzHFMefHJ2"
      },
      "source": [
        "# engineer new categorical AQ features\n",
        "bike_df_cat = bike_df.copy()\n",
        "bike_df_cat['PM10_good'] = bike_df_cat['PM10'].apply(lambda x: 1 if x < 30 else 0)\n",
        "bike_df_cat['PM10_moderate'] = bike_df_cat['PM10'].apply(lambda x: 1 if x < 80 and x >= 31 else 0)\n",
        "bike_df_cat['PM10_unhealthy'] = bike_df_cat['PM10'].apply(lambda x: 1 if x < 150 and x >= 81 else 0)\n",
        "bike_df_cat['PM10_very_unhealthy'] = bike_df_cat['PM10'].apply(lambda x: 1 if x >= 151 else 0)\n",
        "bike_df_cat['PM25_good'] = bike_df_cat['PM2.5'].apply(lambda x: 1 if x < 15 else 0)\n",
        "bike_df_cat['PM25_moderate'] = bike_df_cat['PM2.5'].apply(lambda x: 1 if x < 35 and x >= 16 else 0)\n",
        "bike_df_cat['PM25_unhealthy'] = bike_df_cat['PM2.5'].apply(lambda x: 1 if x < 75 and x >= 36 else 0)\n",
        "bike_df_cat['PM25_very_unhealthy'] = bike_df_cat['PM2.5'].apply(lambda x: 1 if x >= 76 else 0)\n",
        "\n",
        "bike_df_cat[['PM10_good', 'PM10_moderate', 'PM10_unhealthy', 'PM10_very_unhealthy', 'PM25_good', 'PM25_moderate', 'PM25_unhealthy', 'PM25_very_unhealthy']] = bike_df_cat[['PM10_good', 'PM10_moderate', 'PM10_unhealthy', 'PM10_very_unhealthy', 'PM25_good', 'PM25_moderate', 'PM25_unhealthy', 'PM25_very_unhealthy']].shift()\n",
        "\n",
        "bike_df_cat = bike_df_cat.iloc[0:,:]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiRi_2TvfHKQ",
        "outputId": "dadd7fae-4b84-452e-be76-fc8b5638d671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get the optimal window for rolling std for RainM(mm)\n",
        "print(best_window_std(bike_df['RainM(mm)'], bike_df['Trip_Count'], 40))\n",
        "\n",
        "# get the correlation for window size determined by RainM(mm)\n",
        "precip_mean = bike_df['RainM(mm)'].rolling(8).std()[7:-1]\n",
        "pearsonr(precip_mean, bike_df['Trip_Count'][8:])\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{38: 0.061215418070146466, 2: -0.021762566657129716}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.0003705742186305601, 0.9673647401483304)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RKlDIpmfHMg",
        "outputId": "bfd15cf8-483a-4f3a-9933-24fdbc0b485d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get the optimal number for rolling mean window\n",
        "print(best_window(bike_df['WindSpeedM(m/s)'], bike_df['Trip_Count'], 40))\n",
        "\n",
        "# get the correlation for window size determined by wind\n",
        "wind_mean = bike_df['WindSpeedM(m/s)'].rolling(8).mean()[7:-1]\n",
        "pearsonr(wind_mean, bike_df['Trip_Count'][8:])[0]\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{39: 0.023631717822896525, 1: -0.026152704864007892}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0026884178670223413"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GIWLiZtfHMl",
        "outputId": "73b124a0-e035-47b3-c968-6591c6c231e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get the optimal window for rolling std for temperature\n",
        "print(best_window_std(bike_df['WindSpeedM(m/s)'], bike_df['Trip_Count'], 40))\n",
        "\n",
        "# get the correlation for window size determined by wind\n",
        "wind_mean = bike_df['WindSpeedM(m/s)'].rolling(8).std()[7:-1]\n",
        "pearsonr(wind_mean, bike_df['Trip_Count'][8:])\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{38: -0.05679909742989022, 6: -0.11929895283492986}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.11382634433058314, 1.9049735545374817e-36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VuhPK4BKHRY"
      },
      "source": [
        "ENTROPYBIG_mean = bike_df['ENTROPYBIG'].rolling(8).mean()[7:-1]\n",
        "ENTROPYSMALL_mean = bike_df['ENTROPYSMALL'].rolling(8).mean()[7:-1]\n",
        "RESIDENTIAL110_mean = bike_df['110_RESIDENTIAL'].rolling(8).mean()[7:-1]\n",
        "HOUSE111_mean = bike_df['111_HOUSE'].rolling(8).mean()[7:-1]\n",
        "APT112_mean = bike_df['112_APT'].rolling(8).mean()[7:-1]\n",
        "INDUSTRIAL120_mean = bike_df['120_INDUSTRIAL'].rolling(8).mean()[7:-1]\n",
        "INDUSTRIAL121_mean = bike_df['121_INDUSTRIAL'].rolling(8).mean()[7:-1]\n",
        "COMMERCIAL130_mean = bike_df['130_COMMERCIAL'].rolling(8).mean()[7:-1]\n",
        "COMMERCIAL131_WORK_mean = bike_df['131_COMMERCIAL_WORK'].rolling(8).mean()[7:-1]\n",
        "MIXEDUSE132_mean = bike_df['132_MIXEDUSE'].rolling(8).mean()[7:-1]\n",
        "RECREATIONAL140_mean = bike_df['140_RECREATIONAL'].rolling(8).mean()[7:-1]\n",
        "RECREATIONAL141_mean = bike_df['141_RECREATIONAL'].rolling(8).mean()[7:-1]\n",
        "TRANSIT150_mean = bike_df['150_TRANSIT'].rolling(8).mean()[7:-1]\n",
        "PUBLIC160_mean = bike_df['160_PUBLIC'].rolling(8).mean()[7:-1]\n",
        "GREENINFRA_mean = bike_df['GREENINFRA'].rolling(8).mean()[7:-1]\n",
        "POPDensity_mean = bike_df['POPDensity(p/㎢)'].rolling(8).mean()[7:-1]\n",
        "POPGender_mean = bike_df['POPGender(Male/Female)'].rolling(8).mean()[7:-1]\n",
        "Age_under24_mean = bike_df['Age_under24'].rolling(8).mean()[7:-1]\n",
        "PM10_mean = bike_df['PM10'].rolling(8).mean()[7:-1]\n",
        "PM25_mean = bike_df['PM2.5'].rolling(8).mean()[7:-1]\n",
        "COVID_mean = bike_df['COVID'].rolling(8).mean()[7:-1]\n",
        "Metro_station_mean = bike_df['Metro_station'].rolling(8).mean()[7:-1]\n",
        "Metrotrip18_IN_mean = bike_df['18Metrotrip_IN'].rolling(8).mean()[7:-1]\n",
        "Metrotrip18_OUT_mean = bike_df['18Metrotrip_OUT'].rolling(8).mean()[7:-1]\n",
        "Metrotrip_IN_mean = bike_df['Metrotrip_IN'].rolling(8).mean()[7:-1]\n",
        "Metrotrip_OUT_mean = bike_df['Metrotrip_OUT'].rolling(8).mean()[7:-1]\n",
        "Bus_station_mean = bike_df['Bus_station'].rolling(8).mean()[7:-1]\n",
        "BusINCount_mean = bike_df['BusINCount'].rolling(8).mean()[7:-1]\n",
        "BusOUTCount_mean = bike_df['BusOUTCount'].rolling(8).mean()[7:-1]\n",
        "Bike_station_mean = bike_df['Bike_station'].rolling(8).mean()[7:-1]\n",
        "Bike_stand_mean = bike_df['Bike_stand'].rolling(8).mean()[7:-1]\n",
        "BikeRoadCount_mean = bike_df['BikeRoadCount(개)'].rolling(8).mean()[7:-1]\n",
        "BikeRoadDistance_mean = bike_df['BikeRoadDistance(km)'].rolling(8).mean()[7:-1]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMYDMXypfHM4"
      },
      "source": [
        "# code based on implementation on https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/\n",
        "def adf_test(df, col_names):\n",
        "    '''\n",
        "    Function to perform Augmented Dickey-Fuller test on selected timeseries\n",
        "    Args: df = dataframe with timeseries to be tested\n",
        "          col_names = list of names of the timeseries to be tested\n",
        "    Returns: None\n",
        "    '''\n",
        "    for name in col_names:\n",
        "        print ('Results of Augmented Dickey-Fuller Test for {}'.format(name))\n",
        "        result_test = adfuller(df[name], autolag='AIC')\n",
        "        result_output = pd.Series(result_test[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
        "        for key, val in result_test[4].items():\n",
        "            result_output['Critical Value (%s)'%key] = val\n",
        "        print (result_output)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIHcMQ_UfHM7"
      },
      "source": [
        "# create the features that need to be tested\n",
        "# Trip_Count_t-1 was already added to the dataframe\n",
        "\n",
        "testing_feat = ['Trip_Count', 'ENTROPYBIG',\t'ENTROPYSMALL',\t'110_RESIDENTIAL',\t'111_HOUSE',\t'112_APT',\t'120_INDUSTRIAL',\t'121_INDUSTRIAL',\t'130_COMMERCIAL',\t'131_COMMERCIAL_WORK',\t'132_MIXEDUSE',\t'140_RECREATIONAL',\t'141_RECREATIONAL',\t'150_TRANSIT',\t'160_PUBLIC',\t'GREENINFRA',\t'POPDensity(p/㎢)',\t'POPGender(Male/Female)',\t'Age_under24',\t'TempM(°C)',\t'WindSpeedM(m/s)',\t'RainM(mm)',\t'PM10',\t'PM2.5',\t'COVID',\t'Metro_station',\t'18Metrotrip_IN',\t'18Metrotrip_OUT',\t'Metrotrip_IN',\t'Metrotrip_OUT',\t'Bus_station',\t'BusINCount',\t'BusOUTCount',\t'Bike_station',\t'Bike_stand',\t'BikeRoadCount(개)',\t'BikeRoadDistance(km)']\n",
        "\n",
        "testing_df = pd.DataFrame()\n",
        "\n",
        "for col in testing_feat:\n",
        "    col_mean = bike_df[col].rolling(16).mean()[15:-1]\n",
        "    col_std = bike_df[col].rolling(16).std()[15:-1]\n",
        "    testing_df[col+'_mean16'] = col_mean.values\n",
        "    testing_df[col+'_std16'] = col_std.values\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4ZGhH3DfHM_",
        "outputId": "566ab432-f1da-4884-d8dc-96fd5be22b6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# adf test for Trip_Count_t-1\n",
        "temp_cust_1 = bike_df['Trip_Count_t-1'].fillna(0)\n",
        "bike_df_temp = pd.DataFrame(temp_cust_1, columns=['Trip_Count_t-1'])\n",
        "adf_test(bike_df_temp, ['Trip_Count_t-1'])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results of Augmented Dickey-Fuller Test for Trip_Count_t-1\n",
            "Test Statistic                -7.513128e+00\n",
            "p-value                        3.967003e-11\n",
            "#Lags Used                     4.000000e+01\n",
            "Number of Observations Used    1.215900e+04\n",
            "Critical Value (1%)           -3.430888e+00\n",
            "Critical Value (5%)           -2.861778e+00\n",
            "Critical Value (10%)          -2.566897e+00\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeGoYRZsfHOB",
        "outputId": "a23aa374-4744-4a28-82dd-92cce7e3d8b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# adf test for Trip_Count\n",
        "adf_test(bike_df, ['Trip_Count'])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results of Augmented Dickey-Fuller Test for Trip_Count\n",
            "Test Statistic                -7.513455e+00\n",
            "p-value                        3.959547e-11\n",
            "#Lags Used                     4.000000e+01\n",
            "Number of Observations Used    1.215900e+04\n",
            "Critical Value (1%)           -3.430888e+00\n",
            "Critical Value (5%)           -2.861778e+00\n",
            "Critical Value (10%)          -2.566897e+00\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-PrMp1KfHPz"
      },
      "source": [
        "# code based on implementation on https://www.analyticsvidhya.com/blog/2018/09/non-stationary-time-series-python/\n",
        "def kpss_test(df, col_names):\n",
        "    '''\n",
        "    Function to perform KPSS test on selected timeseries\n",
        "    Args: df = dataframe with timeseries to be tested\n",
        "          col_names = list of names of the timeseries to be tested\n",
        "    Returns: None\n",
        "    '''\n",
        "    for name in col_names:\n",
        "        print ('Results of KPSS Test for {}'.format(name))\n",
        "        result_test = kpss(df[name], regression='c', lags='legacy')\n",
        "        result_output = pd.Series(result_test[0:3], index=['Test Statistic','p-value','Lags Used'])\n",
        "        for key, val in result_test[3].items():\n",
        "            result_output['Critical Value (%s)'%key] = val\n",
        "        print (result_output)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDwaAqbhfHQi",
        "outputId": "40f4cfe6-ba96-4fb5-b1e0-3ee05238e4ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# kpss test for Trip_Count_t-1\n",
        "kpss_test(bike_df_temp, ['Trip_Count_t-1'])\n",
        "\n",
        "# kpss test for Trip_Count\n",
        "kpss_test(bike_df, ['Trip_Count'])\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results of KPSS Test for Trip_Count_t-1\n",
            "Test Statistic            3.787181\n",
            "p-value                   0.010000\n",
            "Lags Used                40.000000\n",
            "Critical Value (10%)      0.347000\n",
            "Critical Value (5%)       0.463000\n",
            "Critical Value (2.5%)     0.574000\n",
            "Critical Value (1%)       0.739000\n",
            "dtype: float64\n",
            "Results of KPSS Test for Trip_Count\n",
            "Test Statistic            3.780879\n",
            "p-value                   0.010000\n",
            "Lags Used                40.000000\n",
            "Critical Value (10%)      0.347000\n",
            "Critical Value (5%)       0.463000\n",
            "Critical Value (2.5%)     0.574000\n",
            "Critical Value (1%)       0.739000\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tsa/stattools.py:1709: InterpolationWarning: p-value is smaller than the indicated p-value\n",
            "  warn(\"p-value is smaller than the indicated p-value\", InterpolationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tsa/stattools.py:1709: InterpolationWarning: p-value is smaller than the indicated p-value\n",
            "  warn(\"p-value is smaller than the indicated p-value\", InterpolationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZaYwxSIfHQk"
      },
      "source": [
        "# Trying to lessen trends (make it stationary) via log\n",
        "\n",
        "not_stationary =['ENTROPYBIG_mean16',\t'ENTROPYSMALL_mean16',\t'110_RESIDENTIAL_mean16',\t\n",
        "                 '111_HOUSE_mean16',\t'112_APT_mean16',\t'120_INDUSTRIAL_mean16',\t'121_INDUSTRIAL_mean16',\t\n",
        "                 '130_COMMERCIAL_mean16',\t'131_COMMERCIAL_WORK_mean16',\t'132_MIXEDUSE_mean16',\t'140_RECREATIONAL_mean16',\t\n",
        "                 '141_RECREATIONAL_mean16',\t'150_TRANSIT_mean16',\t'160_PUBLIC_mean16',\t'GREENINFRA_mean16',\t\n",
        "                 'POPDensity(p/㎢)_mean16',\t'POPGender(Male/Female)_mean16',\t'Age_under24_mean16',\t'WindSpeedM(m/s)_mean16',\t\n",
        "                 'Metro_station_mean16',\t'18Metrotrip_IN_mean16',\t'18Metrotrip_OUT_mean16',\t'Metrotrip_IN_mean16',\t\n",
        "                 'Metrotrip_OUT_mean16',\t'Bus_station_mean16',\t'Bike_station_mean16',\t'Bike_stand_mean16',\t\n",
        "                 'BikeRoadCount(개)_mean16',\t'BikeRoadDistance(km)_mean16',\t'Trip_Count_mean16',\t'Trip_Count_t-1_mean16',\t\n",
        "                 'WindSpeedM(m/s)_std16',\t'18Metrotrip_IN_std16',\t'18Metrotrip_OUT_std16',\t'Metrotrip_IN_std16',\t'Metrotrip_OUT_std16']\n",
        "\n",
        "bike_df_temp['Trip_Count_t-1_log'] = [np.log1p(x+1) for x in bike_df_temp['Trip_Count_t-1']]\n",
        "testing_df['ENTROPYBIG_mean16_log'] = [np.log1p(x+1) for x in testing_df['ENTROPYBIG_mean16']]\n",
        "testing_df['ENTROPYSMALL_mean16_log'] = [np.log1p(x+1) for x in testing_df['ENTROPYSMALL_mean16']]\n",
        "testing_df['110_RESIDENTIAL_mean16_log'] = [np.log1p(x+1) for x in testing_df['110_RESIDENTIAL_mean16']]\n",
        "testing_df['111_HOUSE_mean16_log'] = [np.log1p(x+1) for x in testing_df['111_HOUSE_mean16']]\n",
        "testing_df['112_APT_mean16_log'] = [np.log1p(x+1) for x in testing_df['112_APT_mean16']]\n",
        "testing_df['120_INDUSTRIAL_mean16_log'] = [np.log1p(x+1) for x in testing_df['120_INDUSTRIAL_mean16']]\n",
        "testing_df['121_INDUSTRIAL_mean16_log'] = [np.log1p(x+1) for x in testing_df['121_INDUSTRIAL_mean16']]\n",
        "testing_df['130_COMMERCIAL_mean16_log'] = [np.log1p(x+1) for x in testing_df['130_COMMERCIAL_mean16']]\n",
        "testing_df['131_COMMERCIAL_WORK_mean16_log'] = [np.log1p(x+1) for x in testing_df['131_COMMERCIAL_WORK_mean16']]\n",
        "testing_df['132_MIXEDUSE_mean16_log'] = [np.log1p(x+1) for x in testing_df['132_MIXEDUSE_mean16']]\n",
        "testing_df['140_RECREATIONAL_mean16_log'] = [np.log1p(x+1) for x in testing_df['140_RECREATIONAL_mean16']]\n",
        "testing_df['141_RECREATIONAL_mean16_log'] = [np.log1p(x+1) for x in testing_df['141_RECREATIONAL_mean16']]\n",
        "testing_df['150_TRANSIT_mean16_log'] = [np.log1p(x+1) for x in testing_df['150_TRANSIT_mean16']]\n",
        "testing_df['160_PUBLIC_mean16_log'] = [np.log1p(x+1) for x in testing_df['160_PUBLIC_mean16']]\n",
        "testing_df['GREENINFRA_mean16_log'] = [np.log1p(x+1) for x in testing_df['GREENINFRA_mean16']]\n",
        "testing_df['POPDensity(p/㎢)_mean16_log'] = [np.log1p(x+1) for x in testing_df['POPDensity(p/㎢)_mean16']]\n",
        "testing_df['POPGender(Male/Female)_mean16_log'] = [np.log1p(x+1) for x in testing_df['POPGender(Male/Female)_mean16']]\n",
        "testing_df['Age_under24_mean16_log'] = [np.log1p(x+1) for x in testing_df['Age_under24_mean16']]\n",
        "testing_df['WindSpeedM(m/s)_mean16_log'] = [np.log1p(x+1) for x in testing_df['WindSpeedM(m/s)_mean16']]\n",
        "testing_df['Metro_station_mean16_log'] = [np.log1p(x+1) for x in testing_df['Metro_station_mean16']]\n",
        "testing_df['18Metrotrip_IN_mean16_log'] = [np.log1p(x+1) for x in testing_df['18Metrotrip_IN_mean16']]\n",
        "testing_df['18Metrotrip_OUT_mean16_log'] = [np.log1p(x+1) for x in testing_df['18Metrotrip_OUT_mean16']]\n",
        "testing_df['Metrotrip_IN_mean16_log'] = [np.log1p(x+1) for x in testing_df['Metrotrip_IN_mean16']]\n",
        "testing_df['Metrotrip_OUT_mean16_log'] = [np.log1p(x+1) for x in testing_df['Metrotrip_OUT_mean16']]\n",
        "testing_df['Bus_station_mean16_log'] = [np.log1p(x+1) for x in testing_df['Bus_station_mean16']]\n",
        "testing_df['Bike_station_mean16_log'] = [np.log1p(x+1) for x in testing_df['Bike_station_mean16']]\n",
        "testing_df['Bike_stand_mean16_log'] = [np.log1p(x+1) for x in testing_df['Bike_stand_mean16']]\n",
        "testing_df['BikeRoadCount(개)_mean16_log'] = [np.log1p(x+1) for x in testing_df['BikeRoadCount(개)_mean16']]\n",
        "testing_df['BikeRoadDistance(km)_mean16_log'] = [np.log1p(x+1) for x in testing_df['BikeRoadDistance(km)_mean16']]\n",
        "testing_df['Trip_Count_mean16_log'] = [np.log1p(x+1) for x in testing_df['Trip_Count_mean16']]\n",
        "testing_df['WindSpeedM(m/s)_std16_log'] = [np.log1p(x+1) for x in testing_df['WindSpeedM(m/s)_std16']]\n",
        "testing_df['18Metrotrip_IN_std16_log'] = [np.log1p(x+1) for x in testing_df['18Metrotrip_IN_std16']]\n",
        "testing_df['18Metrotrip_OUT_std16_log'] = [np.log1p(x+1) for x in testing_df['18Metrotrip_OUT_std16']]\n",
        "testing_df['Metrotrip_IN_std16_log'] = [np.log1p(x+1) for x in testing_df['Metrotrip_IN_std16']]\n",
        "testing_df['Metrotrip_OUT_std16_log'] = [np.log1p(x+1) for x in testing_df['Metrotrip_OUT_std16']]\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDHL5V38fHRJ",
        "outputId": "5603613b-2e3b-4ce1-aa0b-c0e7d7208da7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# applying differencing to remove trend from Trip_Count\n",
        "bike_df_check = bike_df[['Trip_Count']]\n",
        "bike_df_check['Trip_Count_diff'] = bike_df_check['Trip_Count'] - bike_df_check['Trip_Count'].shift()\n",
        "bike_df_check = bike_df_check.iloc[1:,]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tFZwT31sfHRK",
        "outputId": "dcb37318-84bf-47ff-bba4-e6ebb624a61b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# kpss test for Trip_Count\n",
        "kpss_test(testing_df, ['Trip_Count_mean16_log'])\n",
        "kpss_test(bike_df_temp, ['Trip_Count_t-1_log'])\n",
        "\n",
        "# adf test for Trip_Count\n",
        "adf_test(testing_df, ['Trip_Count_mean16_log'])\n",
        "adf_test(bike_df_temp, ['Trip_Count_t-1_log'])\n",
        "adf_test(bike_df_check, ['Trip_Count_diff'])\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tsa/stattools.py:1709: InterpolationWarning: p-value is smaller than the indicated p-value\n",
            "  warn(\"p-value is smaller than the indicated p-value\", InterpolationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tsa/stattools.py:1709: InterpolationWarning: p-value is smaller than the indicated p-value\n",
            "  warn(\"p-value is smaller than the indicated p-value\", InterpolationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results of KPSS Test for Trip_Count_mean16_log\n",
            "Test Statistic            3.933395\n",
            "p-value                   0.010000\n",
            "Lags Used                40.000000\n",
            "Critical Value (10%)      0.347000\n",
            "Critical Value (5%)       0.463000\n",
            "Critical Value (2.5%)     0.574000\n",
            "Critical Value (1%)       0.739000\n",
            "dtype: float64\n",
            "Results of KPSS Test for Trip_Count_t-1_log\n",
            "Test Statistic            3.874564\n",
            "p-value                   0.010000\n",
            "Lags Used                40.000000\n",
            "Critical Value (10%)      0.347000\n",
            "Critical Value (5%)       0.463000\n",
            "Critical Value (2.5%)     0.574000\n",
            "Critical Value (1%)       0.739000\n",
            "dtype: float64\n",
            "Results of Augmented Dickey-Fuller Test for Trip_Count_mean16_log\n",
            "Test Statistic                -9.399632e+00\n",
            "p-value                        6.237891e-16\n",
            "#Lags Used                     4.000000e+01\n",
            "Number of Observations Used    1.214300e+04\n",
            "Critical Value (1%)           -3.430889e+00\n",
            "Critical Value (5%)           -2.861778e+00\n",
            "Critical Value (10%)          -2.566897e+00\n",
            "dtype: float64\n",
            "Results of Augmented Dickey-Fuller Test for Trip_Count_t-1_log\n",
            "Test Statistic                -7.539283e+00\n",
            "p-value                        3.412011e-11\n",
            "#Lags Used                     4.000000e+01\n",
            "Number of Observations Used    1.215900e+04\n",
            "Critical Value (1%)           -3.430888e+00\n",
            "Critical Value (5%)           -2.861778e+00\n",
            "Critical Value (10%)          -2.566897e+00\n",
            "dtype: float64\n",
            "Results of Augmented Dickey-Fuller Test for Trip_Count_diff\n",
            "Test Statistic                -1.748946e+01\n",
            "p-value                        4.444964e-30\n",
            "#Lags Used                     4.000000e+01\n",
            "Number of Observations Used    1.215800e+04\n",
            "Critical Value (1%)           -3.430888e+00\n",
            "Critical Value (5%)           -2.861778e+00\n",
            "Critical Value (10%)          -2.566897e+00\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAwG8fRYfHSA"
      },
      "source": [
        "# should keep this before the cleaning function has been created\n",
        "bike_df.drop(columns=['COVID/100000', 'weekday'], axis=1, inplace=True)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbDOIrUFfHSC"
      },
      "source": [
        "# drop the timestamp variable\n",
        "bike_df.drop(columns=['date_datetime'], inplace=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfHSsglAfHSD"
      },
      "source": [
        "# specify the window for rolling values\n",
        "window = 8"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ygd0jIvfHSG"
      },
      "source": [
        "# creating rolling values\n",
        "new_feat = ['Trip_Count', 'ENTROPYBIG',\t'ENTROPYSMALL',\t'110_RESIDENTIAL',\t'111_HOUSE',\t'112_APT',\t'120_INDUSTRIAL',\t'121_INDUSTRIAL',\t'130_COMMERCIAL',\t'131_COMMERCIAL_WORK',\t'132_MIXEDUSE',\t'140_RECREATIONAL',\t'141_RECREATIONAL',\t'150_TRANSIT',\t'160_PUBLIC',\t'GREENINFRA',\t'POPDensity(p/㎢)',\t'POPGender(Male/Female)',\t'Age_under24',\t'TempM(°C)',\t'WindSpeedM(m/s)',\t'RainM(mm)',\t'PM10',\t'PM2.5',\t'COVID',\t'Metro_station',\t'18Metrotrip_IN',\t'18Metrotrip_OUT',\t'Metrotrip_IN',\t'Metrotrip_OUT',\t'Bus_station',\t'BusINCount',\t'BusOUTCount',\t'Bike_station',\t'Bike_stand',\t'BikeRoadCount(개)',\t'BikeRoadDistance(km)']\n",
        "\n",
        "temp_df = pd.DataFrame()\n",
        "\n",
        "for col in new_feat:\n",
        "    col_mean = bike_df[col].rolling(window).mean()[(window-1):-1]\n",
        "    col_std = bike_df[col].rolling(window).std()[(window-1):-1]\n",
        "    temp_df[col+'_mean'+str(window)] = col_mean.values\n",
        "    temp_df[col+'_std'+str(window)] = col_std.values"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "MY-slaWAfHSN"
      },
      "source": [
        "# remember to remove the first row from 16 rows from Trip_Count (target label)\n",
        "new_bike_df = bike_df.iloc[window:,:]\n",
        "bike_df_cat = bike_df_cat.iloc[window:,:]\n",
        "new_bike_df.reset_index(drop=True, inplace=True)\n",
        "bike_df_cat.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2f4zB_87fHTA"
      },
      "source": [
        "# merging both dataframes with features\n",
        "final_bike_df = new_bike_df.join(temp_df, how='left')\n",
        "final_bike_df = final_bike_df.merge(bike_df_cat, how='left')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88XKtLV-fHTD"
      },
      "source": [
        "# assigning X and y\n",
        "y = final_bike_df['Trip_Count']\n",
        "X = final_bike_df.drop(columns=['Trip_Count'])\n",
        "\n",
        "X['Date'] = pd.to_datetime(X['Date'], format='%Y-%m-%d').astype(int)\n",
        "X['Date'] = X['Date'].apply(lambda x: str(x))\n",
        "X['date_datetime'] = pd.to_datetime(X['date_datetime'], format='%Y-%m-%d').astype(int)\n",
        "X['date_datetime'] = X['date_datetime'].apply(lambda x: str(x))\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQGH7EZEfHTM"
      },
      "source": [
        "# creating a class that I can use in the ML pipeline that prints out the transformed data that will enter the model\n",
        "class Debug(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        self.shape = X.shape\n",
        "        print(self.shape)\n",
        "        X_df = pd.DataFrame(X)\n",
        "        print(X_df)\n",
        "        # print(X_df.to_string()) # can only be print like this without running LagVars() to avoid crashing\n",
        "        # what other output you want\n",
        "        return X"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3tz-TubfHTQ",
        "outputId": "eacbc538-a2de-45fa-e361-487738dfc40e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# assigning X and y for the univariate naive prediction\n",
        "y_naive = (final_bike_df['Trip_Count'].copy())\n",
        "X_naive = y_naive.copy()\n",
        "X_naive = pd.DataFrame(data=X_naive, columns=['Trip_Count'])\n",
        "\n",
        "# getting the start time\n",
        "start_time = datetime.now()\n",
        "\n",
        "# creating y_pred\n",
        "y_pred = (X_naive.shift())[1:]\n",
        "# adjusting length of the actual target values\n",
        "y_naive = y_naive[1:]\n",
        "\n",
        "# get final time\n",
        "end_time = datetime.now()\n",
        "print('Total running time of naive predictor:', (end_time - start_time).total_seconds())\n",
        "\n",
        "# calculating the scores for the last value method\n",
        "print('RMSE:', np.sqrt(mean_squared_error(y_naive, y_pred)))\n",
        "print('RMSLE:', np.sqrt(mean_squared_log_error(y_naive, y_pred)))\n",
        "print('MAE:', mean_absolute_error(y_naive, y_pred))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total running time of naive predictor: 0.000516\n",
            "RMSE: 793.5107478722404\n",
            "RMSLE: 0.4937500277399892\n",
            "MAE: 468.14723976704124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRV2zwHFfHTR"
      },
      "source": [
        "#### Preparation code for using differenced y for predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YKsPxcdfHTS"
      },
      "source": [
        "y_log = final_bike_df[['Trip_Count']].copy()\n",
        "y_log['Trip_Count'] = y_log['Trip_Count'].apply(lambda x: np.log1p(x+1))\n",
        "y_shift = y_log.shift(1)\n",
        "y_diff = (y_log - y_shift)[1:]\n",
        "X_diff = X[1:]\n",
        "\n",
        "y_diff.reset_index(drop=True, inplace=True)\n",
        "X_diff.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPv4LzjkfHTT"
      },
      "source": [
        "# initializing the model which is a Random Forest model and uses default hyperparameters\n",
        "model_rf_diff = RandomForestRegressor(random_state=42)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT-UyAOSfHTU",
        "outputId": "21a718c1-ca66-4d35-98b9-5404533a823e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# creating and fitting the ML pipeline\n",
        "trend_features = ['Trip_Count_mean'+str(window), 'Trip_Count_std'+str(window), 'Trip_Count_t-1']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('trend_diff', FunctionTransformer(np.log1p, validate=False), trend_features),\n",
        "], remainder='passthrough')\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    #('debug', Debug()) # I have commented this out because it will hinder the execution of this pipeline\n",
        "    ('model', model_rf_diff)\n",
        "])\n",
        "\n",
        "pipeline_rf_diff = pipeline.fit(X_diff, y_diff)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZto4mG3fHTd"
      },
      "source": [
        "# creating a timeseries split of the datasets\n",
        "time_split = TimeSeriesSplit(n_splits=10)\n",
        "\n",
        "# doing cross validation on the chunks of data and calculating scores\n",
        "scores_rf_diff = cross_validate(pipeline_rf_diff, X_diff, y_diff, cv=time_split,\n",
        "                         scoring=['neg_mean_squared_error', 'neg_mean_absolute_error'],\n",
        "                         return_train_score=True, n_jobs=-1)\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "MLiMwZjhfHTe",
        "outputId": "15134407-1318-44ab-df36-1bab12157b88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# root mean squared error\n",
        "print('Average RMSE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_rf_diff['train_neg_mean_squared_error']])/len(scores_rf_diff['train_neg_mean_squared_error']))\n",
        "print('Average RMSE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_rf_diff['test_neg_mean_squared_error']])/len(scores_rf_diff['test_neg_mean_squared_error']))\n",
        "\n",
        "# mean absolute error\n",
        "print('Average MAE train data:', \n",
        "      sum([(-1 * x) for x in scores_rf_diff['train_neg_mean_absolute_error']])/len(scores_rf_diff['train_neg_mean_absolute_error']))\n",
        "print('Average MAE test data:', \n",
        "      sum([(-1 * x) for x in scores_rf_diff['test_neg_mean_absolute_error']])/len(scores_rf_diff['test_neg_mean_absolute_error']))\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average RMSE train data: 0.07879490507231\n",
            "Average RMSE test data: 0.21685512068445348\n",
            "Average MAE train data: 0.0486483235844493\n",
            "Average MAE test data: 0.1434120534800168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYr3NzrdfHTg",
        "outputId": "70c7197b-9309-4d2c-a5aa-880a4469fc73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# getting indices for all folds from timeseriessplit\n",
        "X_train_over = defaultdict()  \n",
        "X_test_over = defaultdict()\n",
        "y_train_over = defaultdict()\n",
        "y_test_over = defaultdict()\n",
        "\n",
        "y_test_index = []\n",
        "y_train_index = []\n",
        "\n",
        "count = 0\n",
        "\n",
        "for train_index, test_index in time_split.split(X_diff):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    \n",
        "    y_test_index.append(test_index)\n",
        "    y_train_index.append(train_index)\n",
        "    \n",
        "    X_train, X_test = X_diff.iloc[train_index], X_diff.iloc[test_index]\n",
        "    y_train, y_test = (np.array(y_diff))[train_index], (np.array(y_diff))[test_index]\n",
        "    X_train_over[count] = X_train\n",
        "    X_test_over[count] = X_test\n",
        "    y_train_over[count] = y_train\n",
        "    y_test_over[count] = y_test\n",
        "    \n",
        "    count += 1"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN: [   0    1    2 ... 1108 1109 1110] TEST: [1111 1112 1113 ... 2216 2217 2218]\n",
            "TRAIN: [   0    1    2 ... 2216 2217 2218] TEST: [2219 2220 2221 ... 3324 3325 3326]\n",
            "TRAIN: [   0    1    2 ... 3324 3325 3326] TEST: [3327 3328 3329 ... 4432 4433 4434]\n",
            "TRAIN: [   0    1    2 ... 4432 4433 4434] TEST: [4435 4436 4437 ... 5540 5541 5542]\n",
            "TRAIN: [   0    1    2 ... 5540 5541 5542] TEST: [5543 5544 5545 ... 6648 6649 6650]\n",
            "TRAIN: [   0    1    2 ... 6648 6649 6650] TEST: [6651 6652 6653 ... 7756 7757 7758]\n",
            "TRAIN: [   0    1    2 ... 7756 7757 7758] TEST: [7759 7760 7761 ... 8864 8865 8866]\n",
            "TRAIN: [   0    1    2 ... 8864 8865 8866] TEST: [8867 8868 8869 ... 9972 9973 9974]\n",
            "TRAIN: [   0    1    2 ... 9972 9973 9974] TEST: [ 9975  9976  9977 ... 11080 11081 11082]\n",
            "TRAIN: [    0     1     2 ... 11080 11081 11082] TEST: [11083 11084 11085 ... 12188 12189 12190]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQj1qFLJfHTi"
      },
      "source": [
        "def split_predict_test(X_train, y_train, X_test, y_test, split):\n",
        "    \n",
        "    pipeline_part = pipeline.fit(X_train[split], y_train[split].ravel())\n",
        "    prediction_test = pipeline_part.predict(X_test[split])\n",
        "    #print('transformed RMSE:', np.sqrt(mean_squared_error(y_test[split], prediction_test)))\n",
        "        \n",
        "    # what are the predictions in absolute terms\n",
        "    y_test_pred_log = prediction_test + y_log.iloc[y_test_index[split]]['Trip_Count']\n",
        "    y_test_pred = np.exp(y_test_pred_log) - 2\n",
        "\n",
        "    # what are the actual values in absolute terms\n",
        "    y_test_true_log = y_test[split] + y_log.iloc[y_test_index[split]]\n",
        "    y_test_true = np.exp(y_test_true_log) - 2 # minus 2 because we added 1 each when doing the log function earlier\n",
        "\n",
        "    # what is the rmse, rmsle and mae\n",
        "    #print('actual RMSE:', np.sqrt(mean_squared_error(y_test_true, y_test_pred)))\n",
        "    #print('actual RMSLE:', np.sqrt(mean_squared_log_error(y_test_true, y_test_pred)))\n",
        "    #print('actual MAE:', mean_absolute_error(y_test_true, y_test_pred))\n",
        "    \n",
        "    rmse = np.sqrt(mean_squared_error(y_test_true, y_test_pred))\n",
        "    rmsle = np.sqrt(mean_squared_log_error(y_test_true, y_test_pred))\n",
        "    mae = mean_absolute_error(y_test_true, y_test_pred)\n",
        "    \n",
        "    list_scores = []\n",
        "    list_scores.extend([rmse, rmsle, mae])\n",
        "    \n",
        "    return list_scores\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82-eo2eXfHTj"
      },
      "source": [
        "def split_predict_train(X_train, y_train, X_test, y_test, split):\n",
        "    \n",
        "    pipeline_part = pipeline.fit(X_train[split], y_train[split].ravel())\n",
        "    prediction_train = pipeline_part.predict(X_train[split])\n",
        "    #print('transformed RMSE:', np.sqrt(mean_squared_error(y_test[split], prediction_test)))\n",
        "        \n",
        "    # what are the predictions in absolute terms\n",
        "    y_train_pred_log = prediction_train + y_log.iloc[y_train_index[split]]['Trip_Count']\n",
        "    y_train_pred = np.exp(y_train_pred_log) - 2\n",
        "\n",
        "    # what are the actual values in absolute terms\n",
        "    y_train_true_log = y_train[split] + y_log.iloc[y_train_index[split]]\n",
        "    y_train_true = np.exp(y_train_true_log) - 2 # minus 2 because we added 1 each when doing the log function earlier\n",
        "\n",
        "    # what is the rmse, rmsle and mae\n",
        "    #print('actual RMSE:', np.sqrt(mean_squared_error(y_test_true, y_test_pred)))\n",
        "    #print('actual RMSLE:', np.sqrt(mean_squared_log_error(y_test_true, y_test_pred)))\n",
        "    #print('actual MAE:', mean_absolute_error(y_test_true, y_test_pred))\n",
        "    \n",
        "    rmse = np.sqrt(mean_squared_error(y_train_true, y_train_pred))\n",
        "    rmsle = np.sqrt(mean_squared_log_error(y_train_true, y_train_pred))\n",
        "    mae = mean_absolute_error(y_train_true, y_train_pred)\n",
        "    \n",
        "    list_scores = []\n",
        "    list_scores.extend([rmse, rmsle, mae])\n",
        "    \n",
        "    return list_scores"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS2EYtzBfHTk"
      },
      "source": [
        "#### 4.4. Random Forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOpp6yGwfHTl"
      },
      "source": [
        "##### doing run through with untransformed y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-wAUv2wfHTl"
      },
      "source": [
        "# initializing the model which is a Random Forest model and uses default hyperparameters\n",
        "model_rf = RandomForestRegressor(bootstrap=False, random_state=15)\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkNMo33gfHTm"
      },
      "source": [
        "# creating and fitting the ML pipeline\n",
        "trend_features = ['Trip_Count_mean'+str(window), 'Trip_Count_std'+str(window), 'Trip_Count_t-1']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('trend_diff', FunctionTransformer(np.log1p, validate=False), trend_features),\n",
        "], remainder='passthrough')\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    #('debug', Debug()) # I have commented this out because it will hinder the execution of this pipeline\n",
        "    ('model', model_rf)\n",
        "])\n",
        "\n",
        "pipeline_rf = pipeline.fit(X, y)\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn1EjppEfHTn"
      },
      "source": [
        "# creating a timeseries split of the datasets\n",
        "time_split = TimeSeriesSplit(n_splits=10)\n",
        "\n",
        "# doing cross validation on the chunks of data and calculating scores\n",
        "scores_rf = cross_validate(pipeline_rf, X, y, cv=time_split,\n",
        "                         scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
        "                                  'neg_mean_squared_log_error'],\n",
        "                         return_train_score=True, n_jobs=-1)\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5nALXlNfHUX",
        "outputId": "aaeced64-bba4-4804-9f42-9524cfd9c798",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# root mean squared error\n",
        "print('Random Forests: Average RMSE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_rf['train_neg_mean_squared_error']])/len(scores_rf['train_neg_mean_squared_error']))\n",
        "print('Random Forests: Average RMSE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_rf['test_neg_mean_squared_error']])/len(scores_rf['test_neg_mean_squared_error']))\n",
        "\n",
        "# mean absolute error\n",
        "print('Random Forests: Average MAE train data:', \n",
        "      sum([(-1 * x) for x in scores_rf['train_neg_mean_absolute_error']])/len(scores_rf['train_neg_mean_absolute_error']))\n",
        "print('Random Forests: Average MAE test data:', \n",
        "      sum([(-1 * x) for x in scores_rf['test_neg_mean_absolute_error']])/len(scores_rf['test_neg_mean_absolute_error']))\n",
        "\n",
        "# root mean squared log error\n",
        "print('Random Forests: Average RMSLE train data:', \n",
        "      sum([(-1 * x) for x in scores_rf['train_neg_mean_squared_log_error']])/len(scores_rf['train_neg_mean_squared_log_error']))\n",
        "print('Random Forests: Average RMSLE test data:', \n",
        "      sum([(-1 * x) for x in scores_rf['test_neg_mean_squared_log_error']])/len(scores_rf['test_neg_mean_squared_log_error']))\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forests: Average RMSE train data: 0.0\n",
            "Random Forests: Average RMSE test data: 638.3157922566836\n",
            "Random Forests: Average MAE train data: 0.0\n",
            "Random Forests: Average MAE test data: 429.7743136281589\n",
            "Random Forests: Average RMSLE train data: 0.0\n",
            "Random Forests: Average RMSLE test data: 0.11288587645527733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkNNY3h8fHUZ"
      },
      "source": [
        "I will use randomizedsearch and gridsearch to tune my hyperparameters for the Random Forest model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da0q8uGmfHUZ"
      },
      "source": [
        "# number of trees in random forest\n",
        "n_estimators = randint(1, 2000)\n",
        "# maximum number of features included in the model\n",
        "max_features = randint(1, 20)\n",
        "# maximum number of levels in tree\n",
        "max_depth = randint(1,10)\n",
        "# minimum number of samples required to split a node\n",
        "min_samples_leaf = randint(1, 10)\n",
        "\n",
        "# create the random grid\n",
        "random_grid_rf = {'model__n_estimators': n_estimators,\n",
        "                   'model__max_depth': max_depth,\n",
        "                   'model__min_samples_leaf': min_samples_leaf,\n",
        "                   'model__max_features': max_features}\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L86v-pmzfHUe"
      },
      "source": [
        "I'm using a try and except argument to load an already tuned model or, if none is available, to run randomsearch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "b5Mu7G60fHUe",
        "outputId": "468f565e-6d7c-49fd-b7a3-18ae40c8215f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check the start time\n",
        "start_time = datetime.now()\n",
        "print(start_time)\n",
        "\n",
        "# instantiate and fit the randomizedsearch class to the random parameters\n",
        "rs_rf = RandomizedSearchCV(pipeline_rf, \n",
        "                        param_distributions=random_grid_rf, \n",
        "                        scoring='neg_mean_squared_error', \n",
        "                        n_jobs=-1,\n",
        "                        cv=time_split,\n",
        "                        n_iter = 5,\n",
        "                        verbose=10,\n",
        "                        random_state=49)\n",
        "rs_rf = rs_rf.fit(X, y)\n",
        "\n",
        "# print the total running time\n",
        "end_time = datetime.now()\n",
        "print('Total running time:', end_time-start_time)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-30 18:43:09.440073\n",
            "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   16.6s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.8min\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fazu3_wifHUl"
      },
      "source": [
        "# Saving the best RandomForest model\n",
        "pickle.dump(rs_rf.best_estimator_, open('randomforest.sav', 'wb'))\n",
        "\n",
        "# change the keys of the best_params dictionary to allow it to be used for the final model\n",
        "fix_best_params_rf = {key[7:]: val for key, val in rs_rf.best_params_.items()}\n",
        "\n",
        "print(fix_best_params_rf)\n",
        "\n",
        "# fit the randomforestregressor with the best_params as hyperparameters\n",
        "model_rf_rs = RandomForestRegressor(**fix_best_params_rf, bootstrap=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL64evhyfHUm"
      },
      "source": [
        "# creating and fitting the ML pipeline\n",
        "trend_features = ['Trip_Count_mean'+str(window), 'Trip_Count_std'+str(window), 'Trip_Count_t-1']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('trend_diff', FunctionTransformer(np.log1p, validate=False), trend_features),\n",
        "], remainder='passthrough')\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    #('debug', Debug()) # I have commented this out because it will hinder the execution of this pipeline\n",
        "    ('model', model_rf_rs)\n",
        "])\n",
        "\n",
        "# fitting x and y to pipeline\n",
        "pipeline_rf_rs = pipeline.fit(X, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb0gfEyNfHUy"
      },
      "source": [
        "# doing cross validation on the chunks of data and calculating scores\n",
        "scores_rf = cross_validate(pipeline_rf_rs, X, y, cv=time_split,\n",
        "                         scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
        "                                  'neg_mean_squared_log_error'],\n",
        "                         return_train_score=True, n_jobs=-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5wPBuLkfHU2"
      },
      "source": [
        "# root mean squared error\n",
        "print('Random Forests: Average RMSE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_rf['train_neg_mean_squared_error']])/len(scores_rf['train_neg_mean_squared_error']))\n",
        "print('Random Forests: Average RMSE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_rf['test_neg_mean_squared_error']])/len(scores_rf['test_neg_mean_squared_error']))\n",
        "\n",
        "# absolute mean error\n",
        "print('Random Forests: Average MAE train data:', \n",
        "      sum([(-1 * x) for x in scores_rf['train_neg_mean_absolute_error']])/len(scores_rf['train_neg_mean_absolute_error']))\n",
        "print('Random Forests: Average MAE test data:', \n",
        "      sum([(-1 * x) for x in scores_rf['test_neg_mean_absolute_error']])/len(scores_rf['test_neg_mean_absolute_error']))\n",
        "\n",
        "# root mean squared log error\n",
        "print('Random Forests: Average RMSLE train data:', \n",
        "      sum([(-1 * x) for x in scores_rf['train_neg_mean_squared_log_error']])/len(scores_rf['train_neg_mean_squared_log_error']))\n",
        "print('Random Forests: Average RMSLE test data:', \n",
        "      sum([(-1 * x) for x in scores_rf['test_neg_mean_squared_log_error']])/len(scores_rf['test_neg_mean_squared_log_error']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2iby6cSfHU5"
      },
      "source": [
        "# assign lists of parameters to be used in gridsearch\n",
        "param_grid_rf = {'model__max_depth': [8, 9],\n",
        "                 'model__max_features': [18, 19],\n",
        "                 'model__min_samples_leaf': [5, 6],\n",
        "                 'model__n_estimators': [1926, 1930]\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv2qLnIjfHU6"
      },
      "source": [
        "# use gridsearch to search around the randomizedsearch best parameters and further improve the model\n",
        "gs_rf = GridSearchCV(pipeline_rf, \n",
        "                  param_grid=param_grid_rf, \n",
        "                  scoring='neg_mean_squared_error', \n",
        "                  verbose = 10,\n",
        "                  n_jobs=-1, \n",
        "                  cv=time_split)\n",
        "gs_rf = gs_rf.fit(X, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDLGPxmMfHU9"
      },
      "source": [
        "# Saving the best RandomForest model\n",
        "pickle.dump(gs_rf.best_estimator_, open('randomforest.sav', 'wb'))\n",
        "\n",
        "# change the keys of the best_params dictionary to allow it to be used for the final model\n",
        "fix_best_params_rf = {key[7:]: val for key, val in gs_rf.best_params_.items()}\n",
        "\n",
        "print(fix_best_params_rf)\n",
        "\n",
        "# fit the randomforestregressor with the best_params as hyperparameters\n",
        "model_rf_tuned = RandomForestRegressor(**fix_best_params_rf, bootstrap=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBTMMjuZfHU_"
      },
      "source": [
        "# creating and fitting the ML pipeline\n",
        "trend_features = ['Trip_Count_mean'+str(window), 'Trip_Count_std'+str(window), 'Trip_Count_t-1']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('trend_diff', FunctionTransformer(np.log1p, validate=False), trend_features),\n",
        "], remainder='passthrough')\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    #('debug', Debug()) # I have commented this out because it will hinder the execution of this pipeline\n",
        "    ('model', model_rf_tuned)\n",
        "])\n",
        "\n",
        "# fitting x and y to pipeline\n",
        "pipeline_rf_tuned = pipeline.fit(X, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEywb5jBfHVB"
      },
      "source": [
        "# check the start time\n",
        "start_time = datetime.now()\n",
        "\n",
        "# doing cross validation on the chunks of data and calculating scores\n",
        "scores_rf_tuned = cross_validate(pipeline_rf_tuned, X, y, cv=time_split,\n",
        "                         scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
        "                                  'neg_mean_squared_log_error'],\n",
        "                         return_train_score=True, n_jobs=-1)\n",
        "\n",
        "# print the total running time\n",
        "end_time = datetime.now()\n",
        "print('Total cross validation time for random forests:', (end_time-start_time).total_seconds())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcZ_WPTOfHVC"
      },
      "source": [
        "# root mean squared error\n",
        "print('Random Forests: Average RMSE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_rf_tuned['train_neg_mean_squared_error']])/len(scores_rf_tuned['train_neg_mean_squared_error']))\n",
        "print('Random Forests: Average RMSE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_rf_tuned['test_neg_mean_squared_error']])/len(scores_rf_tuned['test_neg_mean_squared_error']))\n",
        "\n",
        "# mean absolute error\n",
        "print('Random Forests: Average MAE train data:', \n",
        "      sum([(-1 * x) for x in scores_rf_tuned['train_neg_mean_absolute_error']])/len(scores_rf_tuned['train_neg_mean_absolute_error']))\n",
        "print('Random Forests: Average MAE test data:', \n",
        "      sum([(-1 * x) for x in scores_rf_tuned['test_neg_mean_absolute_error']])/len(scores_rf_tuned['test_neg_mean_absolute_error']))\n",
        "\n",
        "# root mean squared log error\n",
        "print('Random Forests: Average RMSLE train data:', \n",
        "      sum([(-1 * x) for x in scores_rf_tuned['train_neg_mean_squared_log_error']])/len(scores_rf_tuned['train_neg_mean_squared_log_error']))\n",
        "print('Random Forests: Average RMSLE test data:', \n",
        "      sum([(-1 * x) for x in scores_rf_tuned['test_neg_mean_squared_log_error']])/len(scores_rf_tuned['test_neg_mean_squared_log_error']))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "1lx9z3NyfHVD"
      },
      "source": [
        "# plot feature importance\n",
        "plt.figure(figsize=[12,9])\n",
        "importances = list(pipeline_rf_tuned.steps[1][1].feature_importances_)\n",
        "\n",
        "imp_dict = {key: val for key, val in zip(list(X.columns), importances)}\n",
        "sorted_feats = sorted(imp_dict.items(), key=lambda x:x[1], reverse=True)\n",
        "x_val = [x[0] for x in sorted_feats]\n",
        "y_val = [x[1] for x in sorted_feats]\n",
        "\n",
        "sb.barplot(y_val, x_val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvy2WIdVfHXd"
      },
      "source": [
        "##### running model with differenced y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k0iOfpKfHXd"
      },
      "source": [
        "# get the final scores for the differenced data\n",
        "split = 10\n",
        "all_scores_test = []\n",
        "all_scores_train = []\n",
        "\n",
        "for i in range(split):\n",
        "    scores_test = split_predict_test(X_train_over, y_train_over, X_test_over, y_test_over, i)\n",
        "    all_scores_test.append(scores_test)\n",
        "    scores_train = split_predict_train(X_train_over, y_train_over, X_test_over, y_test_over, i)\n",
        "    all_scores_train.append(scores_train)\n",
        "    \n",
        "rmse_test = []\n",
        "rmsle_test = []\n",
        "mae_test = []\n",
        "rmse_train = []\n",
        "rmsle_train = []\n",
        "mae_train = []\n",
        "\n",
        "for vals in all_scores_test:\n",
        "    rmse_test.append(vals[0])\n",
        "    rmsle_test.append(vals[1])\n",
        "    mae_test.append(vals[2])\n",
        "    \n",
        "for vals in all_scores_train:\n",
        "    rmse_train.append(vals[0])\n",
        "    rmsle_train.append(vals[1])\n",
        "    mae_train.append(vals[2])\n",
        "    \n",
        "print('Overall Test RMSE:', sum(rmse_test)/split)\n",
        "print('Overall Test RMSLE:', sum(rmsle_test)/split)\n",
        "print('Overall Test MAE:', sum(mae_test)/split)\n",
        "\n",
        "print('Overall Train RMSE:', sum(rmse_train)/split)\n",
        "print('Overall Train RMSLE:', sum(rmsle_train)/split)\n",
        "print('Overall Train MAE:', sum(mae_train)/split)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCYkG7yBfHYf"
      },
      "source": [
        "##### Removing some features based on feature importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4lSXPqWfHYf"
      },
      "source": [
        "# how many features are in the dataset currently:\n",
        "len(x_val)\n",
        "weekday_feats = ['weekday_3', 'weekday_1', 'weekday_2', 'weekday_4', 'weekday_5', 'weekday_6']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSTmSrjWfHYl"
      },
      "source": [
        "# check how the model performance without certain features that are very unimportant\n",
        "X_feat_imp = X.drop(columns=weekday_feats)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CxSCR5zfHYn"
      },
      "source": [
        "# creating and fitting the ML pipeline\n",
        "trend_features = ['Trip_Count_mean'+str(window), 'Trip_Count_std'+str(window)]#, 'Trip_Count_t-1']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('trend_diff', FunctionTransformer(np.log1p, validate=False), trend_features),\n",
        "], remainder='passthrough')\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    #('debug', Debug()) # I have commented this out because it will hinder the execution of this pipeline\n",
        "    ('model', model_rf_tuned)\n",
        "])\n",
        "\n",
        "# fitting x and y to pipeline\n",
        "pipeline_rf_tuned = pipeline.fit(X_feat_imp, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXlVKcLkfHYo"
      },
      "source": [
        "# doing cross validation on the chunks of data and calculating scores\n",
        "scores_rf_tuned = cross_validate(pipeline_rf_tuned, X_feat_imp, y, cv=time_split,\n",
        "                         scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
        "                                  'neg_mean_squared_log_error'],\n",
        "                         return_train_score=True, n_jobs=-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGsUzQW-fHYr"
      },
      "source": [
        "# root mean squared error\n",
        "print('Random Forests: Average RMSE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_rf_tuned['train_neg_mean_squared_error']])/len(scores_rf_tuned['train_neg_mean_squared_error']))\n",
        "print('Random Forests: Average RMSLE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_rf_tuned['test_neg_mean_squared_error']])/len(scores_rf_tuned['test_neg_mean_squared_error']))\n",
        "\n",
        "# mean absolute error\n",
        "print('Random Forests: Average MAE train data:', \n",
        "      sum([(-1 * x) for x in scores_rf_tuned['train_neg_mean_absolute_error']])/len(scores_rf_tuned['train_neg_mean_absolute_error']))\n",
        "print('Random Forests: Average MAE test data:', \n",
        "      sum([(-1 * x) for x in scores_rf_tuned['test_neg_mean_absolute_error']])/len(scores_rf_tuned['test_neg_mean_absolute_error']))\n",
        "\n",
        "# root mean squared log error\n",
        "print('Random Forests: Average RMSLE train data:', \n",
        "      sum([(-1 * x) for x in scores_rf_tuned['train_neg_mean_squared_log_error']])/len(scores_rf_tuned['train_neg_mean_squared_log_error']))\n",
        "print('Random Forests: Average RMSLE test data:', \n",
        "      sum([(-1 * x) for x in scores_rf_tuned['test_neg_mean_squared_log_error']])/len(scores_rf_tuned['test_neg_mean_squared_log_error']))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJZiEg70fHYv"
      },
      "source": [
        "Removing seemingly unimportant features does not lead to a better result. Unimportant features are simply not considered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M7bNuNtfHYw"
      },
      "source": [
        "#### 4.2. AdaBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84PI2ONtfHYw"
      },
      "source": [
        "##### running AdaBoost with undifference y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV4AcD0WfHYw"
      },
      "source": [
        "# initializing AdaBoost model with default hyperparameters\n",
        "model_ada = AdaBoostRegressor(random_state=42, base_estimator=DecisionTreeRegressor())\n",
        "\n",
        "# creating and fitting the ML pipeline\n",
        "trend_features = ['Trip_Count_mean'+str(window), 'Trip_Count_std'+str(window), 'Trip_Count_t-1']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('trend_diff', FunctionTransformer(np.log1p, validate=False), trend_features),\n",
        "], remainder='passthrough')\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    #('debug', Debug()) # I have commented this out because it will hinder the execution of this pipeline\n",
        "    ('model', model_ada)\n",
        "])\n",
        "\n",
        "pipeline_ada = pipeline.fit(X, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gsvyd6UjfHYx"
      },
      "source": [
        "# creating a timeseries split of the datasets\n",
        "time_split = TimeSeriesSplit(n_splits=10)\n",
        "\n",
        "# doing cross validation on the chunks of data and calculating scores\n",
        "scores_ada = cross_validate(pipeline_ada, X, y, cv=time_split,\n",
        "                         scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
        "                                  'neg_mean_squared_log_error'],\n",
        "                         return_train_score=True, n_jobs=-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfJgMvfxfHYy"
      },
      "source": [
        "# root mean squared error\n",
        "print('AdaBoost: Average RMSE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_ada['train_neg_mean_squared_error']])/len(scores_ada['train_neg_mean_squared_error']))\n",
        "print('AdaBoost: Average RMSE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_ada['test_neg_mean_squared_error']])/len(scores_ada['test_neg_mean_squared_error']))\n",
        "\n",
        "# mean absolute error\n",
        "print('AdaBoost: Average MAE train data:', \n",
        "      sum([(-1 * x) for x in scores_ada['train_neg_mean_absolute_error']])/len(scores_ada['train_neg_mean_absolute_error']))\n",
        "print('AdaBoost: Average MAE test data:', \n",
        "      sum([(-1 * x) for x in scores_ada['test_neg_mean_absolute_error']])/len(scores_ada['test_neg_mean_absolute_error']))\n",
        "\n",
        "# root mean squared log error\n",
        "print('AdaBoost: Average RMSLE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_ada['train_neg_mean_squared_log_error']])/len(scores_ada['train_neg_mean_squared_log_error']))\n",
        "print('AdaBoost: Average RMSLE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_ada['test_neg_mean_squared_log_error']])/len(scores_ada['test_neg_mean_squared_log_error']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIbduX8-fHY3"
      },
      "source": [
        "Tuning the hyperparameters of AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsqoasjSfHY3"
      },
      "source": [
        "# number of estimators in AdaBoost model\n",
        "n_estimators = randint(100, 1000)\n",
        "# learning rate\n",
        "learning_rate = uniform(0.001, 0.05)\n",
        "# max_depth\n",
        "max_depth = randint(1, 8)\n",
        "\n",
        "# Create the random grid\n",
        "random_grid_ada = {'model__n_estimators': n_estimators,\n",
        "                   'model__learning_rate': learning_rate,\n",
        "                   'model__base_estimator__max_depth': max_depth}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5SKilp5fHY5"
      },
      "source": [
        "# check the start time\n",
        "start_time = datetime.now()\n",
        "print(start_time)\n",
        "\n",
        "# instantiate and fit the randomizedsearch class to the random parameters\n",
        "rs_ada = RandomizedSearchCV(pipeline_ada, \n",
        "                        param_distributions=random_grid_ada, \n",
        "                        scoring='neg_mean_squared_error', \n",
        "                        n_jobs=-1,\n",
        "                        cv=time_split,\n",
        "                        n_iter = 5,\n",
        "                        verbose=10,\n",
        "                        random_state=40)\n",
        "rs_ada = rs_ada.fit(X, y)\n",
        "\n",
        "# print the total running time\n",
        "end_time = datetime.now()\n",
        "print('Total running time:', end_time-start_time)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Jbg3SXWwfHY6"
      },
      "source": [
        "# Saving the best RandomForest model\n",
        "pickle.dump(rs_ada.best_estimator_, open('adaboost.sav', 'wb'))\n",
        "\n",
        "# change the keys of the best_params dictionary to allow it to be used for the final model\n",
        "fix_best_params_ada = {key[7:]: val for key, val in rs_ada.best_params_.items()}\n",
        "\n",
        "print(fix_best_params_ada)\n",
        "max_depth = fix_best_params_ada['base_estimator__max_depth']\n",
        "\n",
        "# fit the randomforestregressor with the best_params as hyperparameters\n",
        "model_ada_tuned = AdaBoostRegressor(DecisionTreeRegressor(max_depth=max_depth),\n",
        "                                    learning_rate=fix_best_params_ada['learning_rate'], \n",
        "                                    n_estimators=fix_best_params_ada['n_estimators'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDNivp-MfHY7"
      },
      "source": [
        "# creating and fitting the ML pipeline\n",
        "trend_features = ['Trip_Count_mean'+str(window), 'Trip_Count_std'+str(window), 'Trip_Count_t-1']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('trend_diff', FunctionTransformer(np.log1p, validate=False), trend_features),\n",
        "], remainder='passthrough')\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    #('debug', Debug()) # I have commented this out because it will hinder the execution of this pipeline\n",
        "    ('model', model_ada_tuned)\n",
        "])\n",
        "\n",
        "pipeline_ada_tuned = pipeline.fit(X, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPYCp6HIfHY8"
      },
      "source": [
        "# creating a timeseries split of the datasets\n",
        "time_split = TimeSeriesSplit(n_splits=10)\n",
        "\n",
        "# doing cross validation on the chunks of data and calculating scores\n",
        "scores_ada_tuned = cross_validate(pipeline_ada_tuned, X, y, cv=time_split,\n",
        "                         scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
        "                                  'neg_mean_squared_log_error'],\n",
        "                         return_train_score=True, n_jobs=-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG9Uee0HfHZD"
      },
      "source": [
        "# root mean squared error\n",
        "print('AdaBoost: Average RMSE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_ada_tuned['train_neg_mean_squared_error']])/len(scores_ada_tuned['train_neg_mean_squared_error']))\n",
        "print('AdaBoost: Average RMSE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_ada_tuned['test_neg_mean_squared_error']])/len(scores_ada_tuned['test_neg_mean_squared_error']))\n",
        "\n",
        "# mean absolute error\n",
        "print('AdaBoost: Average MAE train data:', \n",
        "      sum([(-1 * x) for x in scores_ada_tuned['train_neg_mean_absolute_error']])/len(scores_ada_tuned['train_neg_mean_absolute_error']))\n",
        "print('AdaBoost: Average MAE test data:', \n",
        "      sum([(-1 * x) for x in scores_ada_tuned['test_neg_mean_absolute_error']])/len(scores_ada_tuned['test_neg_mean_absolute_error']))\n",
        "\n",
        "# root mean squared log error\n",
        "print('AdaBoost: Average RMSLE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_ada_tuned['train_neg_mean_squared_log_error']])/len(scores_ada_tuned['train_neg_mean_squared_log_error']))\n",
        "print('AdaBoost: Average RMSLEtest data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_ada_tuned['test_neg_mean_squared_log_error']])/len(scores_ada_tuned['test_neg_mean_squared_log_error']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg9Ip-QcfHZE"
      },
      "source": [
        "# specify some values for hyperparameters around the values chosen by randomizedsearch\n",
        "grid_param_ada = {'model__learning_rate': [0.003, 0.004, 0.0332],\n",
        "                  'model__n_estimators': [100, 265],\n",
        "                  'model__base_estimator__max_depth': [5, 6, 7]}\n",
        "\n",
        "\n",
        "# use gridsearch to search around the randomizedsearch best parameters and further improve the model\n",
        "gs_ada = GridSearchCV(pipeline_ada, \n",
        "                  param_grid=grid_param_ada, \n",
        "                  scoring='neg_mean_squared_error',\n",
        "                  verbose = 10,\n",
        "                  n_jobs=-1, \n",
        "                  cv=time_split)\n",
        "\n",
        "gs_ada = gs_ada.fit(X, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCTXoptBfHZF"
      },
      "source": [
        "# Saving the best RandomForest model\n",
        "#pickle.dump(gs_ada.best_estimator_, open('adaboost.sav', 'wb'))\n",
        "\n",
        "# change the keys of the best_params dictionary to allow it to be used for the final model\n",
        "fix_best_params_ada = {key[7:]: val for key, val in gs_ada.best_params_.items()}\n",
        "\n",
        "print(fix_best_params_ada)\n",
        "\n",
        "max_depth = fix_best_params_ada['base_estimator__max_depth']\n",
        "\n",
        "# fit the randomforestregressor with the best_params as hyperparameters\n",
        "model_ada_tuned = AdaBoostRegressor(DecisionTreeRegressor(max_depth=max_depth),\n",
        "                                    learning_rate=fix_best_params_ada['learning_rate'], \n",
        "                                    n_estimators=fix_best_params_ada['n_estimators'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUbZeKWYfHZG"
      },
      "source": [
        "# creating and fitting the ML pipeline\n",
        "trend_features = ['Trip_Count_mean'+str(window), 'Trip_Count_std'+str(window), 'Trip_Count_t-1']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('trend_diff', FunctionTransformer(np.log1p, validate=False), trend_features),\n",
        "], remainder='passthrough')\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    #('debug', Debug()) # I have commented this out because it will hinder the execution of this pipeline\n",
        "    ('model', model_ada_tuned)\n",
        "])\n",
        "\n",
        "pipeline_ada_tuned = pipeline.fit(X, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG1L-MExfHZM"
      },
      "source": [
        "# creating a timeseries split of the datasets\n",
        "time_split = TimeSeriesSplit(n_splits=10)\n",
        "\n",
        "# check the start time\n",
        "start_time = datetime.now()\n",
        "\n",
        "# doing cross validation on the chunks of data and calculating scores\n",
        "scores_ada_tuned = cross_validate(pipeline_ada_tuned, X, y, cv=time_split,\n",
        "                         scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
        "                                  'neg_mean_squared_log_error'],\n",
        "                         return_train_score=True, n_jobs=-1)\n",
        "\n",
        "# print the total running time\n",
        "end_time = datetime.now()\n",
        "print('Total cross validation time for AdaBoost:', (end_time-start_time).total_seconds())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-si_HyrfHZO"
      },
      "source": [
        "# root mean squared error\n",
        "print('AdaBoost: Average RMSE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_ada_tuned['train_neg_mean_squared_error']])/len(scores_ada_tuned['train_neg_mean_squared_error']))\n",
        "print('AdaBoost: Average RMSE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_ada_tuned['test_neg_mean_squared_error']])/len(scores_ada_tuned['test_neg_mean_squared_error']))\n",
        "\n",
        "# mean average error\n",
        "print('AdaBoost: Average MAE train data:', \n",
        "      sum([(-1 * x) for x in scores_ada_tuned['train_neg_mean_absolute_error']])/len(scores_ada_tuned['train_neg_mean_absolute_error']))\n",
        "print('AdaBoost: Average MAE test data:', \n",
        "      sum([(-1 * x) for x in scores_ada_tuned['test_neg_mean_absolute_error']])/len(scores_ada_tuned['test_neg_mean_absolute_error']))\n",
        "\n",
        "# root mean squared log error\n",
        "print('AdaBoost: Average RMSLE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_ada_tuned['train_neg_mean_squared_log_error']])/len(scores_ada_tuned['train_neg_mean_squared_log_error']))\n",
        "print('AdaBoost: Average RMSLE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_ada_tuned['test_neg_mean_squared_log_error']])/len(scores_ada_tuned['test_neg_mean_squared_log_error']))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNbJYVs9fHZS"
      },
      "source": [
        "# plot feature importance\n",
        "plt.figure(figsize=[12,9])\n",
        "importances = list(pipeline_ada_tuned.steps[1][1].feature_importances_)\n",
        "\n",
        "imp_dict = {key: val for key, val in zip(list(X.columns), importances)}\n",
        "sorted_feats = sorted(imp_dict.items(), key=lambda x:x[1], reverse=True)\n",
        "x_val = [x[0] for x in sorted_feats]\n",
        "y_val = [x[1] for x in sorted_feats]\n",
        "\n",
        "#importances.sort(reverse=True)\n",
        "sb.barplot(y_val, x_val)\n",
        "#importances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjkbKk2rfHZS"
      },
      "source": [
        "##### running AdaBoost with differenced y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-YKnZBAfHZT"
      },
      "source": [
        "# get the final scores for the differenced data\n",
        "split = 10\n",
        "all_scores_test = []\n",
        "all_scores_train = []\n",
        "\n",
        "for i in range(split):\n",
        "    scores_test = split_predict_test(X_train_over, y_train_over, X_test_over, y_test_over, i)\n",
        "    all_scores_test.append(scores_test)\n",
        "    scores_train = split_predict_train(X_train_over, y_train_over, X_test_over, y_test_over, i)\n",
        "    all_scores_train.append(scores_train)\n",
        "    \n",
        "rmse_test = []\n",
        "rmsle_test = []\n",
        "mae_test = []\n",
        "rmse_train = []\n",
        "rmsle_train = []\n",
        "mae_train = []\n",
        "\n",
        "for vals in all_scores_test:\n",
        "    rmse_test.append(vals[0])\n",
        "    rmsle_test.append(vals[1])\n",
        "    mae_test.append(vals[2])\n",
        "    \n",
        "for vals in all_scores_train:\n",
        "    rmse_train.append(vals[0])\n",
        "    rmsle_train.append(vals[1])\n",
        "    mae_train.append(vals[2])\n",
        "    \n",
        "print('Overall Test RMSE:', sum(rmse_test)/split)\n",
        "print('Overall Test RMSLE:', sum(rmsle_test)/split)\n",
        "print('Overall Test MAE:', sum(mae_test)/split)\n",
        "\n",
        "print('Overall Train RMSE:', sum(rmse_train)/split)\n",
        "print('Overall Train RMSLE:', sum(rmsle_train)/split)\n",
        "print('Overall Train MAE:', sum(mae_train)/split)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KTSe07sfHZU"
      },
      "source": [
        "##### checking how certain features influence the overall performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3esiGOjvfHZV"
      },
      "source": [
        "# check how the model performance without certain features that are very unimportant\n",
        "X_feat_imp = X.drop(columns=['weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFlw5yyJfHZW"
      },
      "source": [
        "# creating and fitting the ML pipeline\n",
        "trend_features = ['Trip_Count_mean'+str(window), 'Trip_Count_std'+str(window)]#, 'Trip_Count_t-1']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('trend_diff', FunctionTransformer(np.log1p, validate=False), trend_features),\n",
        "], remainder='passthrough')\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    #('debug', Debug()) # I have commented this out because it will hinder the execution of this pipeline\n",
        "    ('model', model_ada_tuned)\n",
        "])\n",
        "\n",
        "pipeline_ada_tuned = pipeline.fit(X_feat_imp, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qedR39WfHZX"
      },
      "source": [
        "# creating a timeseries split of the datasets\n",
        "time_split = TimeSeriesSplit(n_splits=10)\n",
        "\n",
        "# doing cross validation on the chunks of data and calculating scores\n",
        "scores_ada_tuned = cross_validate(pipeline_ada_tuned, X_feat_imp, y, cv=time_split,\n",
        "                         scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
        "                                  'neg_mean_squared_log_error'],\n",
        "                         return_train_score=True, n_jobs=-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "AHToaAxJfHZY"
      },
      "source": [
        "# root mean squared error\n",
        "print('AdaBoost: Average RMSE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_ada_tuned['train_neg_mean_squared_error']])/len(scores_ada_tuned['train_neg_mean_squared_error']))\n",
        "print('AdaBoost: Average RMSE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_ada_tuned['test_neg_mean_squared_error']])/len(scores_ada_tuned['test_neg_mean_squared_error']))\n",
        "\n",
        "# mean average error\n",
        "print('AdaBoost: Average MAE train data:', \n",
        "      sum([(-1 * x) for x in scores_ada_tuned['train_neg_mean_absolute_error']])/len(scores_ada_tuned['train_neg_mean_absolute_error']))\n",
        "print('AdaBoost: Average MAE test data:', \n",
        "      sum([(-1 * x) for x in scores_ada_tuned['test_neg_mean_absolute_error']])/len(scores_ada_tuned['test_neg_mean_absolute_error']))\n",
        "\n",
        "# root mean squared log error\n",
        "print('AdaBoost: Average RMSLE train data:', \n",
        "      sum([(-1 * x) for x in scores_ada_tuned['train_neg_mean_squared_log_error']])/len(scores_ada_tuned['train_neg_mean_squared_log_error']))\n",
        "print('AdaBoost: Average RMSLE test data:', \n",
        "      sum([(-1 * x) for x in scores_ada_tuned['test_neg_mean_squared_log_error']])/len(scores_ada_tuned['test_neg_mean_squared_log_error']))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MakQlHnwfHZZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmz0XFGmfHZZ"
      },
      "source": [
        "#### 4.3. XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMEUeFxJfHZa"
      },
      "source": [
        "##### running XGBoost with undifferenced y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTjdTlZnfHZa"
      },
      "source": [
        "# initializing XGBoost model with default hyperparameters\n",
        "model_xgb = xgb.XGBRegressor(random_state=42)\n",
        "\n",
        "# creating and fitting the ML pipeline\n",
        "trend_features = ['Trip_Count_mean'+str(window), 'Trip_Count_std'+str(window), 'Trip_Count_t-1']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('trend_diff', FunctionTransformer(np.log1p, validate=False), trend_features),\n",
        "], remainder='passthrough')\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    #('debug', Debug()) # I have commented this out because it will hinder the execution of this pipeline\n",
        "    ('model', model_xgb)\n",
        "])\n",
        "\n",
        "pipeline_xgb = pipeline.fit(X, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7O-BjeYfHZe"
      },
      "source": [
        "# creating a timeseries split of the datasets\n",
        "time_split = TimeSeriesSplit(n_splits=10)\n",
        "\n",
        "# doing cross validation on the chunks of data and calculating scores\n",
        "scores_xgb = cross_validate(pipeline_xgb, X, y, cv=time_split,\n",
        "                         scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
        "                                  'neg_mean_squared_log_error'],\n",
        "                         return_train_score=True, n_jobs=-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5Ty1vYhfHZf"
      },
      "source": [
        "# root mean squared error\n",
        "print('XGBoost: Average RMSE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_xgb['train_neg_mean_squared_error']])/len(scores_xgb['train_neg_mean_squared_error']))\n",
        "print('XGBoost: Average RMSE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_xgb['test_neg_mean_squared_error']])/len(scores_xgb['test_neg_mean_squared_error']))\n",
        "\n",
        "# mean absolute error\n",
        "print('XGBoost: Average MAE train data:', \n",
        "      sum([(-1 * x) for x in scores_xgb['train_neg_mean_absolute_error']])/len(scores_xgb['train_neg_mean_absolute_error']))\n",
        "print('XGBoost: Average MAE test data:', \n",
        "      sum([(-1 * x) for x in scores_xgb['test_neg_mean_absolute_error']])/len(scores_xgb['test_neg_mean_absolute_error']))\n",
        "\n",
        "# root mean squared log error\n",
        "print('XGBoost: Average RMSLE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_xgb['train_neg_mean_squared_log_error']])/len(scores_xgb['train_neg_mean_squared_log_error']))\n",
        "print('XGBoost: Average RMSLE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_xgb['test_neg_mean_squared_log_error']])/len(scores_xgb['test_neg_mean_squared_log_error']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS_nn5XVfHZg"
      },
      "source": [
        "# alpha\n",
        "alpha = uniform(0.2, 0.5)\n",
        "# learning rate\n",
        "learning_rate = uniform(0, 1)\n",
        "# colsample_bytree\n",
        "colsample_bytree = uniform(0, 1)\n",
        "# max depth\n",
        "n_estimators = randint(300, 1000)\n",
        "# min child weight\n",
        "min_child_weight = randint(5, 10)\n",
        "# max_depth\n",
        "max_depth = randint(1, 5)\n",
        "# subsample\n",
        "# subsample = uniform(0, 1)\n",
        "\n",
        "# Create the random grid\n",
        "random_grid_xgb = {'model__n_estimators': n_estimators,\n",
        "                   'model__learning_rate': learning_rate,\n",
        "                   'model__reg_alpha': alpha,\n",
        "                   'model__colsample_bytree': colsample_bytree,\n",
        "                   'model__min_child_weight': min_child_weight,\n",
        "                   'model__max_depth': max_depth}\n",
        "                   #'model__subsample': subsample}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3XYiHbRfHZh"
      },
      "source": [
        "# check the start time\n",
        "start_time = datetime.now()\n",
        "print(start_time)\n",
        "\n",
        "# instantiate and fit the randomizedsearch class to the random parameters\n",
        "rs_xgb = RandomizedSearchCV(pipeline_xgb, \n",
        "                        param_distributions=random_grid_xgb, \n",
        "                        scoring='neg_mean_squared_error', \n",
        "                        n_jobs=-1,\n",
        "                        cv=time_split,\n",
        "                        n_iter = 10,\n",
        "                        verbose=10,\n",
        "                        random_state=10)\n",
        "rs_xgb = rs_xgb.fit(X, y)\n",
        "\n",
        "# print the total running time\n",
        "end_time = datetime.now()\n",
        "print('Total running time:', end_time-start_time)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbrO45C_fHZk"
      },
      "source": [
        "# Saving the best RandomForest model\n",
        "pickle.dump(rs_xgb.best_estimator_, open('xgboost.sav', 'wb'))\n",
        "\n",
        "# change the keys of the best_params dictionary to allow it to be used for the final model\n",
        "fix_best_params_xgb = {key[7:]: val for key, val in rs_xgb.best_params_.items()}\n",
        "\n",
        "print(fix_best_params_xgb)\n",
        "\n",
        "# fit the randomforestregressor with the best_params as hyperparameters\n",
        "model_xgb_rs = xgb.XGBRegressor(**fix_best_params_xgb)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pX8CBfAfHZl"
      },
      "source": [
        "# creating and fitting the ML pipeline\n",
        "trend_features = ['Trip_Count_mean'+str(window), 'Trip_Count_std'+str(window), 'Trip_Count_t-1']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('trend_diff', FunctionTransformer(np.log1p, validate=False), trend_features),\n",
        "], remainder='passthrough')\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    #('debug', Debug()) # I have commented this out because it will hinder the execution of this pipeline\n",
        "    ('model', model_xgb_rs)\n",
        "])\n",
        "\n",
        "pipeline_xgb_rs = pipeline.fit(X, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBSHvtbffHZv"
      },
      "source": [
        "# creating a timeseries split of the datasets\n",
        "time_split = TimeSeriesSplit(n_splits=10)\n",
        "\n",
        "# doing cross validation on the chunks of data and calculating scores\n",
        "scores_xgb_rs = cross_validate(pipeline_xgb_rs, X, y, cv=time_split,\n",
        "                         scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
        "                                  'neg_mean_squared_log_error'],\n",
        "                         return_train_score=True, n_jobs=-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYssC9uffHZw"
      },
      "source": [
        "# root mean squared error\n",
        "print('XGBoost: Average RMSE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_xgb_rs['train_neg_mean_squared_error']])/len(scores_xgb_rs['train_neg_mean_squared_error']))\n",
        "print('XGBoost: Average RMSE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_xgb_rs['test_neg_mean_squared_error']])/len(scores_xgb_rs['test_neg_mean_squared_error']))\n",
        "\n",
        "# mean absolute error\n",
        "print('XGBoost: Average MAE train data:', \n",
        "      sum([(-1 * x) for x in scores_xgb_rs['train_neg_mean_absolute_error']])/len(scores_xgb_rs['train_neg_mean_absolute_error']))\n",
        "print('XGBoost: Average MAE test data:', \n",
        "      sum([(-1 * x) for x in scores_xgb_rs['test_neg_mean_absolute_error']])/len(scores_xgb_rs['test_neg_mean_absolute_error']))\n",
        "\n",
        "# root mean squared log error\n",
        "print('XGBoost: Average RMSLE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_xgb_rs['train_neg_mean_squared_log_error']])/len(scores_xgb_rs['train_neg_mean_squared_log_error']))\n",
        "print('XGBoost: Average RMSLE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_xgb_rs['test_neg_mean_squared_log_error']])/len(scores_xgb_rs['test_neg_mean_squared_log_error']))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IIA8TELafHZ4"
      },
      "source": [
        "# specify some values for hyperparameters around the values chosen by randomizedsearch\n",
        "grid_param_xgb = {'model__n_estimators': [664, 650],\n",
        "                   'model__learning_rate': [0.35, 0.04],\n",
        "                   'model__alpha': [0.636, 0.6],\n",
        "                   'model__colsample_bytree': [0.85, 0.9],\n",
        "                   'model__min_child_weight': [7, 8],\n",
        "                   'model__max_depth': [1, 2]}\n",
        "                   #'model__subsample': [0.98, 0.90]}\n",
        "\n",
        "# use gridsearch to search around the randomizedsearch best parameters and further improve the model\n",
        "gs_xgb = GridSearchCV(pipeline_xgb, \n",
        "                  param_grid=grid_param_xgb, \n",
        "                  scoring='neg_mean_squared_error', \n",
        "                  verbose = 10,\n",
        "                  n_jobs=-1, \n",
        "                  cv=time_split)\n",
        "\n",
        "gs_xgb = gs_xgb.fit(X, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LG752yHfHZ5"
      },
      "source": [
        "# Saving the best XGB model\n",
        "pickle.dump(gs_xgb.best_estimator_, open('xgboost.sav', 'wb'))\n",
        "\n",
        "# change the keys of the best_params dictionary to allow it to be used for the final model\n",
        "fix_best_params_xgb = {key[7:]: val for key, val in gs_xgb.best_params_.items()}\n",
        "\n",
        "print(fix_best_params_xgb)\n",
        "\n",
        "# fit the randomforestregressor with the best_params as hyperparameters\n",
        "model_xgb_tuned = xgb.XGBRegressor(**fix_best_params_xgb)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Iy4nGtpcfHZ9"
      },
      "source": [
        "# creating and fitting the ML pipeline\n",
        "trend_features = ['Trip_Count_mean'+str(window), 'Trip_Count_std'+str(window), 'Trip_Count_t-1']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('trend_diff', FunctionTransformer(np.log1p, validate=False), trend_features),\n",
        "], remainder='passthrough')\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    #('debug', Debug()) # I have commented this out because it will hinder the execution of this pipeline\n",
        "    ('model', model_xgb_tuned)\n",
        "])\n",
        "\n",
        "pipeline_xgb_tuned = pipeline.fit(X, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqjcgVOKfHaB"
      },
      "source": [
        "# creating a timeseries split of the datasets\n",
        "time_split = TimeSeriesSplit(n_splits=10)\n",
        "\n",
        "# check the start time\n",
        "start_time = datetime.now()\n",
        "\n",
        "# doing cross validation on the chunks of data and calculating scores\n",
        "scores_xgb_tuned = cross_validate(pipeline_xgb_tuned, X, y, cv=time_split,\n",
        "                         scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
        "                                  'neg_mean_squared_log_error'],\n",
        "                         return_train_score=True, n_jobs=-1)\n",
        "\n",
        "# print the total running time\n",
        "end_time = datetime.now()\n",
        "print('Total cross validation time for XGBBoost:', (end_time-start_time).total_seconds())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptZlX3ETfHaN"
      },
      "source": [
        "# root mean squared error\n",
        "print('XGBoost: Average RMSE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_xgb_tuned['train_neg_mean_squared_error']])/len(scores_xgb_tuned['train_neg_mean_squared_error']))\n",
        "print('XGBoost: Average RMSE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_xgb_tuned['test_neg_mean_squared_error']])/len(scores_xgb_tuned['test_neg_mean_squared_error']))\n",
        "\n",
        "# mean absolute error\n",
        "print('XGBoost: Average MAE train data:', \n",
        "      sum([(-1 * x) for x in scores_xgb_tuned['train_neg_mean_absolute_error']])/len(scores_xgb_tuned['train_neg_mean_absolute_error']))\n",
        "print('XGBoost: Average MAE test data:', \n",
        "      sum([(-1 * x) for x in scores_xgb_tuned['test_neg_mean_absolute_error']])/len(scores_xgb_tuned['test_neg_mean_absolute_error']))\n",
        "\n",
        "# root mean squared log error\n",
        "print('XGBoost: Average RMSLE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_xgb_tuned['train_neg_mean_squared_log_error']])/len(scores_xgb_tuned['train_neg_mean_squared_log_error']))\n",
        "print('XGBoost: Average RMSLE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_xgb_tuned['test_neg_mean_squared_log_error']])/len(scores_xgb_tuned['test_neg_mean_squared_log_error']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV8RSeMcfHaP"
      },
      "source": [
        "# map the feature importances to the feature names\n",
        "xgb_feats = X.columns\n",
        "xgb_feats_dict = defaultdict()\n",
        "count = 0\n",
        "\n",
        "for item in xgb_feats:\n",
        "    xgb_feats_dict['f'+str(count)] = item\n",
        "    count += 1\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpy1uJAkfHbI"
      },
      "source": [
        "# Plot feature importance\n",
        "fig, ax = plt.subplots(figsize=(20, 15))\n",
        "xgb.plot_importance(model_xgb_tuned, importance_type='weight', ax=ax)\n",
        "\n",
        "# rename the y axis labels to the actual feature names\n",
        "locs, labels = plt.yticks()\n",
        "\n",
        "new_names = []\n",
        "for item in labels:\n",
        "    for key, name in xgb_feats_dict.items():\n",
        "        if key == item.get_text():\n",
        "            new_names.append(name)\n",
        "\n",
        "ax.set_yticklabels(new_names);\n",
        "            \n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gjAniNofHbg"
      },
      "source": [
        "##### running XGBoost with differenced y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Is96_gKsfHbi"
      },
      "source": [
        "# get the final scores for the differenced data\n",
        "split = 10\n",
        "all_scores_test = []\n",
        "all_scores_train = []\n",
        "\n",
        "for i in range(split):\n",
        "    scores_test = split_predict_test(X_train_over, y_train_over, X_test_over, y_test_over, i)\n",
        "    all_scores_test.append(scores_test)\n",
        "    scores_train = split_predict_train(X_train_over, y_train_over, X_test_over, y_test_over, i)\n",
        "    all_scores_train.append(scores_train)\n",
        "    \n",
        "rmse_test = []\n",
        "rmsle_test = []\n",
        "mae_test = []\n",
        "rmse_train = []\n",
        "rmsle_train = []\n",
        "mae_train = []\n",
        "\n",
        "for vals in all_scores_test:\n",
        "    rmse_test.append(vals[0])\n",
        "    rmsle_test.append(vals[1])\n",
        "    mae_test.append(vals[2])\n",
        "    \n",
        "for vals in all_scores_train:\n",
        "    rmse_train.append(vals[0])\n",
        "    rmsle_train.append(vals[1])\n",
        "    mae_train.append(vals[2])\n",
        "    \n",
        "print('Overall Test RMSE:', sum(rmse_test)/split)\n",
        "print('Overall Test RMSLE:', sum(rmsle_test)/split)\n",
        "print('Overall Test MAE:', sum(mae_test)/split)\n",
        "\n",
        "print('Overall Train RMSE:', sum(rmse_train)/split)\n",
        "print('Overall Train RMSLE:', sum(rmsle_train)/split)\n",
        "print('Overall Train MAE:', sum(mae_train)/split)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDpXNxSIfHbj"
      },
      "source": [
        "##### checking how certain features influence the overall performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_F3Ep0QfHbj"
      },
      "source": [
        "# check how the model performance without certain features that are very unimportant\n",
        "X_feat_imp = X.drop(columns=['weekday_1', 'weekday_3', 'weekday_4', 'weekday_6',\n",
        "                             'hot', 'cold', 'cool', 'warm'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DULDEIgnfHby"
      },
      "source": [
        "# creating and fitting the ML pipeline\n",
        "trend_features = ['Trip_Count_mean'+str(window), 'Trip_Count_std'+str(window), 'Trip_Count_t-1']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('trend_diff', FunctionTransformer(np.log1p, validate=False), trend_features),\n",
        "], remainder='passthrough')\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    #('debug', Debug()) # I have commented this out because it will hinder the execution of this pipeline\n",
        "    ('model', model_xgb_tuned)\n",
        "])\n",
        "\n",
        "pipeline_xgb_tuned = pipeline.fit(X_feat_imp, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJdAvgG5fHb2"
      },
      "source": [
        "# creating a timeseries split of the datasets\n",
        "time_split = TimeSeriesSplit(n_splits=10)\n",
        "\n",
        "# doing cross validation on the chunks of data and calculating scores\n",
        "scores_xgb_tuned = cross_validate(pipeline_xgb_tuned, X_feat_imp, y, cv=time_split,\n",
        "                         scoring=['neg_mean_squared_error', 'neg_mean_absolute_error',\n",
        "                                  'neg_mean_squared_log_error'],\n",
        "                         return_train_score=True, n_jobs=-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKkbNpa7fHb3"
      },
      "source": [
        "# root mean squared error\n",
        "print('XGBoost: Average RMSE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_xgb_tuned['train_neg_mean_squared_error']])/len(scores_xgb_tuned['train_neg_mean_squared_error']))\n",
        "print('XGBoost: Average RMSE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_xgb_tuned['test_neg_mean_squared_error']])/len(scores_xgb_tuned['test_neg_mean_squared_error']))\n",
        "\n",
        "# mean absolute error\n",
        "print('XGBoost: Average MAE train data:', \n",
        "      sum([(-1 * x) for x in scores_xgb_tuned['train_neg_mean_absolute_error']])/len(scores_xgb_tuned['train_neg_mean_absolute_error']))\n",
        "print('XGBoost: Average MAE test data:', \n",
        "      sum([(-1 * x) for x in scores_xgb_tuned['test_neg_mean_absolute_error']])/len(scores_xgb_tuned['test_neg_mean_absolute_error']))\n",
        "\n",
        "# root mean squared log error\n",
        "print('XGBoost: Average RMSLE train data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_xgb_tuned['train_neg_mean_squared_log_error']])/len(scores_xgb_tuned['train_neg_mean_squared_log_error']))\n",
        "print('XGBoost: Average RMSLE test data:', \n",
        "      sum([np.sqrt(-1 * x) for x in scores_xgb_tuned['test_neg_mean_squared_log_error']])/len(scores_xgb_tuned['test_neg_mean_squared_log_error']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc4YX78AfHb6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9sRMXsLfHb7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLIJOeDlfHb9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
